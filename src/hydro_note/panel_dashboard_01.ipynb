{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d212da2-66f8-4b6a-8a13-21b0d9958f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration\n",
    "import os\n",
    "import sys\n",
    "\n",
    "DATA_DIR = \"../hydro_dash/data/studies\"\n",
    "# adding project dirs to path so code may be referenced from the notebook\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../evaluation/')\n",
    "sys.path.insert(0, '../evaluation/queries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b25a2e-39df-4e5d-9fd8-9b73a4f82be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import utils, config\n",
    "import queries2 # need to fix path to use original queries\n",
    "#import dask_geopandas\n",
    "import duckdb as ddb\n",
    "#import spatialpandas as sp\n",
    "#import hvplot.pandas # noqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669573a-1947-4a17-8299-3d4fb08e15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from evaluation import utils, config\n",
    "import queries2 # need to fix path to use original queries\n",
    "import dask_geopandas\n",
    "\n",
    "def get_all_catchment_metrics():\n",
    "    basins_gdf = utils.parquet_to_gdf(config.HUC10_PARQUET_FILEPATH)\n",
    "    query = queries2.calculate_catchment_metrics(\n",
    "        config.MEDIUM_RANGE_FORCING_PARQUET,\n",
    "        config.FORCING_ANALYSIS_ASSIM_PARQUET,\n",
    "        group_by=[\"reference_time, catchment_id\"],\n",
    "        order_by=[\"reference_time, catchment_id\"],\n",
    "        filters=[\n",
    "            {\n",
    "                \"column\": \"1\",\n",
    "                \"operator\": \"=\",\n",
    "                \"value\": 1\n",
    "            },\n",
    "#            {\n",
    "#                \"column\": \"catchment_id\",\n",
    "#                \"operator\": \"like\",\n",
    "#                \"value\": \"\" + huc2.value + \"%\"\n",
    "#            },\n",
    "#            {\n",
    "#                \"column\": \"reference_time\",\n",
    "#                \"operator\": \"=\",\n",
    "#                \"value\": \"2023-01-01 18:00:00\"\n",
    "#            }            \n",
    "       ]\n",
    "    )\n",
    "    df = ddb.query(query).to_df()\n",
    "    gdf_map = basins_gdf.merge(df, left_on=\"huc10\", right_on=\"catchment_id\")\n",
    "    return gdf_map\n",
    "\n",
    "\n",
    "dask_df = dask_geopandas.from_geopandas(get_all_catchment_metrics(), npartitions=32)\n",
    "dask_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b0cf8-e0a8-407d-8f02-421dbecb22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dask_df['huc2'] = dask_df['huc10'].str[:2]\n",
    "#print(gdf.dtypes)\n",
    "dask_df['huc2'] = dask_df['huc2'].astype(\"int\")\n",
    "dask_df['huc10'] = dask_df['huc10'].astype(\"string\")\n",
    "dask_df['name'] = dask_df['name'].astype(\"string\")\n",
    "dask_df['reference_time'] = dask_df['reference_time'].astype(\"datetime64[ns]\")\n",
    "dask_df['catchment_id'] = dask_df['catchment_id'].astype(\"string\")\n",
    "dask_df['time'] = dask_df['reference_time'].astype(int)/ 10**9\n",
    "dask_df['time'] = dask_df['time'].astype(\"int\") # needs the extra pass to actually maintain int type\n",
    "dask_df['huc2'] = dask_df['huc2'].astype(\"int\") # needs the extra pass to actually maintain int type\n",
    "\n",
    "dask_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8fe44-63f3-4a93-8750-84ffa0b4b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#centroid = dask_df[[\"geometry\"]].dissolve().centroid\n",
    "#print(centroid.x, centroid.y)\n",
    "tst = dask_df['reference_time'].unique().compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f1c21-64d3-4084-a61b-2435965b241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = dask_df[(dask_df['huc2']==1) & (dask_df['time'] == 1672531200)]\n",
    "tst[['geometry', 'bias']].hvplot.polygons()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807131d4-89ce-483c-9ed5-a3d96f31da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv, geoviews as gv, param, dask.dataframe as dd, cartopy.crs as crs\n",
    "import panel as pn\n",
    "from datetime import datetime as dt\n",
    "from bokeh.models import HoverTool\n",
    "#import datetime as dt\n",
    "\n",
    "from colorcet import cm\n",
    "from holoviews.operation.datashader import rasterize, shade, regrid\n",
    "from holoviews.streams import RangeXY\n",
    "\n",
    "hv.extension('bokeh', logo=False)\n",
    "pn.extension(loading_spinner='dots', loading_color='#00aa41', sizing_mode=\"stretch_width\")\n",
    "\n",
    "opts = dict(width=900,\n",
    "            height=600,\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            bgcolor='black',\n",
    "            show_grid=False)\n",
    "cmaps = ['fire','bgy','bgyw','bmy','gray','kbc']\n",
    "\n",
    "\n",
    "class HydroExplorer(param.Parameterized):\n",
    "    alpha      = param.Magnitude(default=0.75, doc=\"Alpha value for the map opacity\")\n",
    "    cmap       = param.ObjectSelector(cm['bgyw'], objects={c:cm[c] for c in cmaps})\n",
    "    _max_time  = int(dask_df[\"time\"].max().compute())\n",
    "    _min_time  = int(dask_df[\"time\"].min().compute())\n",
    "    time       = param.Integer(_min_time, bounds=(_min_time, _max_time))\n",
    "    #time       = param.ObjectSelector(default=int(dask_df[\"time\"].min().compute()), objects=dask_df['time'].unique().compute())\n",
    "    #time       = param.Date(dask_df[\"reference_time\"].min().compute(),\n",
    "    #                                     bounds=(dask_df[\"reference_time\"].min().compute(), dask_df[\"reference_time\"].max().compute()))\n",
    "    #time       = param.ObjectSelector(default=dask_df[\"reference_time\"].min().compute(), objects=sorted(dask_df[\"reference_time\"].unique().compute()))\n",
    "    #time       = pn.widgets.DateSlider(name='reference_time', start=dask_df[\"reference_time\"].min().compute(), end=dask_df[\"reference_time\"].max().compute())\n",
    "    huc2       = param.ObjectSelector(default=1, objects=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18])\n",
    "    #huc2       = param.Integer(default=int(dask_df['huc2'].min().compute()), bounds=(int(dask_df['huc2'].min().compute()), int(dask_df['huc2'].max().compute())))\n",
    "    #reference_time_max = dask_df['reference_time'].max().compute()\n",
    "    #reference_time_min = dask_df['reference_time'].min().compute()\n",
    "    #reference_time = datetime_range_slider = pn.widgets.DatetimeRangeSlider(\n",
    "    #                                                                        name='reference_time',\n",
    "    #                                                                        start=dt.datetime(reference_time_min.year, reference_time_min.month, reference_time_min.day), \n",
    "    #                                                                        end=dt.datetime(reference_time_max.year, reference_time_max.month, reference_time_max.day),\n",
    "    #                                                                        value=(dt.datetime(reference_time_min.year, reference_time_min.month, reference_time_min.day), dt.datetime(reference_time_max.year, reference_time_max.month, reference_time_max.day)),\n",
    "    #                                                                        step=10000\n",
    "    #                                                                    )\n",
    "\n",
    "    render_rasterized = True\n",
    "    \n",
    "    @param.depends('huc2', 'time')\n",
    "    def polygons(self):\n",
    "        rslt_df = dask_df[(dask_df['huc2']==self.huc2) & (dask_df['time']==self.time)]\n",
    "        #rslt_df = dask_df[(dask_df['huc2']==self.huc2) & (dask_df['reference_time'] == '' + str(self.time) + '')]\n",
    "        #rslt_df = rslt_df.to_crs(\"EPSG:3395\")\n",
    "        hover = HoverTool(tooltips=[('Name', '@name'),('Bias', '@bias')])\n",
    "        return gv.Polygons(rslt_df.compute())\n",
    "\n",
    "\n",
    "    def view(self,**kwargs):\n",
    "        self.render_rasterized = True\n",
    "        polygons = hv.DynamicMap(self.polygons).opts(tools=['hover'], toolbar='above')\n",
    "        tiles = gv.tile_sources.StamenTerrain().apply.opts(alpha=self.param.alpha, **opts)\n",
    "        if self.render_rasterized == False:\n",
    "            final_map = tiles * polygons\n",
    "        else:\n",
    "            agg = rasterize(polygons, width=600, height=400, precompute=True).opts(hv.opts.Points(alpha=0.1, hover_alpha=0.2, size=10))\n",
    "            final_map = (tiles * shade(agg, cmap=self.param.cmap))\n",
    "        return final_map\n",
    "\n",
    "hydro = HydroExplorer(name=\"data explorer\")\n",
    "pn.Column(hydro.param, hydro.view()).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a36733-2d8b-4776-b0c1-c44315c3671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv, geoviews as gv, param, dask.dataframe as dd, cartopy.crs as crs\n",
    "import panel as pn\n",
    "from datetime import datetime as dt\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "from colorcet import cm\n",
    "from holoviews.operation.datashader import rasterize, shade, regrid, datashade\n",
    "from holoviews.streams import Stream, param\n",
    "from holoviews import streams\n",
    "from holoviews.plotting.links import DataLink\n",
    "\n",
    "hv.extension('bokeh', logo=False)\n",
    "pn.extension(loading_spinner='dots', loading_color='#00aa41', sizing_mode=\"stretch_width\")\n",
    "\n",
    "opts = dict(width=900,\n",
    "            height=600,\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            bgcolor='black',\n",
    "            show_grid=False)\n",
    "cmaps = ['fire','bgy','bgyw','bmy','gray','kbc']\n",
    "huc2 = 1\n",
    "name = \"test\"\n",
    "time = 1672531200\n",
    "\n",
    "class HydroExplorer(param.Parameterized):\n",
    "    alpha      = param.Magnitude(default=0.75, doc=\"Alpha value for the map opacity\")\n",
    "    cmap       = param.ObjectSelector(cm['bgyw'], objects={c:cm[c] for c in cmaps})\n",
    "    time       = param.Integer(int(dask_df[\"time\"].min().compute()), bounds=(int(dask_df['time'].min().compute()), int(dask_df['time'].max().compute())))\n",
    "    #time       = param.Date(dt.fromtimestamp(dask_df[\"reference_time\"].min().compute()),\n",
    "    #                                     bounds=(dt.fromtimestamp(dask_df[\"reference_time\"].min().compute()), dt.fromtimestamp(dask_df[\"reference_time\"].max().compute())))\n",
    "    #time       = pn.widgets.DateSlider(name='reference_time', start=dask_df[\"reference_time\"].min().compute(), end=dask_df[\"reference_time\"].max().compute())\n",
    "    huc2       = param.ObjectSelector(default=1, objects=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18])\n",
    "    #huc2       = param.Integer(default=int(dask_df['huc2'].min().compute()), bounds=(int(dask_df['huc2'].min().compute()), int(dask_df['huc2'].max().compute())))\n",
    "    render_rasterized = True\n",
    "    \n",
    "    @param.depends('huc2', 'time')\n",
    "    def polygons(self):\n",
    "        rslt_df = dask_df[(dask_df['huc2']==self.huc2) & (dask_df['time']==self.time)]\n",
    "        #rslt_df = rslt_df.to_crs(\"EPSG:3395\")\n",
    "        tooltips = [\n",
    "            ('Name', '@name'),\n",
    "            ('Bias', '@bias')\n",
    "        ]\n",
    "        hover = HoverTool(tooltips=tooltips)\n",
    "        points = gv.Polygons(rslt_df.compute()).opts(tools=[hover], toolbar='above')#, vdims=['name', 'bias'])\n",
    "        \n",
    "        if rslt_df['geometry'].count().compute() < 50: \n",
    "            self.render_rasterized = False\n",
    "        else:\n",
    "            self.render_rasterized = True\n",
    "\n",
    "        #if self.hour != (0, 24): points = points.select(dropoff_hour=self.hour)\n",
    "        return points\n",
    "    \n",
    "\n",
    "    def view(self,**kwargs):\n",
    "        self.render_rasterized = False\n",
    "        polygons = hv.DynamicMap(self.polygons)#.opts(tools=[hover], toolbar='above')\n",
    "        rslt_df = dask_df[(dask_df['huc2']==self.huc2) & (dask_df['time']==self.time)]\n",
    "        table = hv.Table(rslt_df[['name', 'bias']].compute(), [('name', 'Name'), ('bias', 'Bias')])\n",
    "        DataLink(polygons, table)\n",
    "        tiles = gv.tile_sources.StamenTerrain().apply.opts(alpha=self.param.alpha, **opts)\n",
    "        if self.render_rasterized == False:\n",
    "            final_map = (tiles * polygons) + table\n",
    "        else:\n",
    "            tooltips = [\n",
    "                ('Name', '@name'),\n",
    "                ('Bias', '@bias'),\n",
    "                ('Test', 'What!')\n",
    "            ]\n",
    "            hover = HoverTool(tooltips=tooltips)\n",
    "            agg = rasterize(polygons, width=600, height=400, precompute=True).opts(hv.opts.Points(tools=[hover], alpha=0.1, hover_alpha=0.2, size=10))\n",
    "            final_map = ((tiles * shade(agg, cmap=self.param.cmap)) + table).cols(1)\n",
    "        return final_map\n",
    "\n",
    "hydro = HydroExplorer(name=\"data explorer\")\n",
    "pn.Row(hydro.param, hydro.view()).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52037fb3-ff58-4151-a7d7-d05d93e3785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import datashade\n",
    "import numpy as np\n",
    "\n",
    "points = hv.Points(np.random.multivariate_normal((0,0), [[0.1, 0.1], [0.1, 1.0]], (500000,)))\n",
    "\n",
    "\n",
    "def filter_points(points, x_range, y_range):\n",
    "    if x_range is None or y_range is None:\n",
    "        return points\n",
    "    return points[x_range, y_range]\n",
    "\n",
    "def hover_points(points, threshold=5000):\n",
    "    if len(points) > threshold:\n",
    "        return points.iloc[:0]\n",
    "    return points\n",
    "\n",
    "range_stream = hv.streams.RangeXY(source=points)\n",
    "streams=[range_stream]\n",
    "\n",
    "threshold = pn.widgets.IntSlider(name='Threshold', start=1000, end=10000, step=100)\n",
    "filtered = points.apply(filter_points, streams=streams)\n",
    "hover = filtered.apply(hover_points, threshold=threshold)\n",
    "shaded = datashade(filtered, width=400, height=400, streams=streams)\n",
    "\n",
    "dynamic_hover = (shaded * hover).opts(\n",
    "    hv.opts.Points(tools=['hover'], alpha=0.1, hover_alpha=0.2, size=10))\n",
    "\n",
    "pn.Column(threshold, dynamic_hover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232e5a3-b41e-4d7b-8aa1-e2c09dc6c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.DynamicMap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26846894-e611-4415-8590-372415b1b639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
