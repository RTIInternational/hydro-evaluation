{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877757a0-69be-4c7c-b1fd-6e4460ff7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# adding project dirs to path so code may be referenced from the notebook\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51601028-c397-4070-a33d-d47f7dc21ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import config\n",
    "import utils\n",
    "import importlib\n",
    "import dask\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "import importlib\n",
    "import grid_to_parquet\n",
    "importlib.reload(grid_to_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6738f6-60a4-479a-b0c3-d4ef363fb68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=12, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab16212-1b16-41ff-8a5f-92abcb10a66a",
   "metadata": {},
   "source": [
    "# Fetch Forcing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a494731-54ba-4662-946d-e4afdce3da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some criteria\n",
    "ingest_forecast_days = 9\n",
    "forecast_interval_hrs = 6\n",
    "start_dt = datetime(2023, 1, 10) # First one is at 00Z in date\n",
    "td = timedelta(hours=forecast_interval_hrs)\n",
    "number_of_forecasts = int(ingest_forecast_days * 24/forecast_interval_hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d925a22f-b090-4901-873a-2dbc6d2c5b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(datetime.now())\n",
    "# Loop though forecasts, fetch and insert\n",
    "for f in range(number_of_forecasts):\n",
    "    reference_time = start_dt + td * f\n",
    "    ref_time_str = reference_time.strftime(\"%Y%m%dT%HZ\")\n",
    "\n",
    "    print(f\"Start download of {ref_time_str}\")\n",
    "\n",
    "    blob_list = grid_to_parquet.list_blobs_forcing(\n",
    "        configuration = \"forcing_medium_range\",\n",
    "        reference_time = ref_time_str,\n",
    "        must_contain = \"forcing\"\n",
    "    )\n",
    "\n",
    "    dfs = []\n",
    "    for blob_name in blob_list:\n",
    "        df = dask.delayed(grid_to_parquet.calculate_map_forcing)(\n",
    "            blob_name, \n",
    "            use_cache=False, \n",
    "            weights_filepath=config.HUC10_MEDIUM_RANGE_WEIGHTS_FILEPATH\n",
    "        )\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Join all timesteps into single pd.DataFrame\n",
    "    results = dask.compute(*dfs)\n",
    "    df = pd.concat(results)\n",
    "\n",
    "    # Save as parquet file\n",
    "    parquet_filepath = os.path.join(config.MEDIUM_RANGE_FORCING_PARQUET, f\"{ref_time_str}.parquet\")\n",
    "    utils.make_parent_dir(parquet_filepath)\n",
    "    df.to_parquet(parquet_filepath)\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    # Print out some DataFrame stats\n",
    "    # print(df.info(verbose=True, memory_usage='deep'))\n",
    "    # print(df.memory_usage(index=True, deep=True))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c83bb-7d8a-43ce-82d4-08bf57aad1a8",
   "metadata": {},
   "source": [
    "# Fetch Assim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae07445-5667-4f77-92bf-2b89c4c8980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some criteria\n",
    "start_dt = datetime(2022, 12, 18)\n",
    "number_of_days = 40\n",
    "\n",
    "# Loop though forecasts, fetch and insert\n",
    "for f in range(number_of_days):\n",
    "    issue_date = start_dt + timedelta(days=f)\n",
    "    issue_date_str = issue_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "    print(f\"Start download of {issue_date_str}\")\n",
    "\n",
    "    blob_list = grid_to_parquet.list_blobs_assim(\n",
    "        configuration = \"forcing_analysis_assim\",\n",
    "        issue_date = issue_date_str,\n",
    "        must_contain = \"tm00.conus\"\n",
    "    )\n",
    "\n",
    "    dfs = []\n",
    "    for blob_name in blob_list:\n",
    "        df = dask.delayed(grid_to_parquet.calculate_map_assim)(\n",
    "            blob_name,\n",
    "            use_cache=False, \n",
    "            weights_filepath=config.HUC10_MEDIUM_RANGE_WEIGHTS_FILEPATH\n",
    "        )\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Join all timesteps into single pd.DataFrame\n",
    "    %time \n",
    "    results = dask.compute(*dfs)\n",
    "    df = pd.concat(results)\n",
    "\n",
    "    # Save as parquet file\n",
    "    parquet_filepath = os.path.join(config.FORCING_ANALYSIS_ASSIM_PARQUET, f\"{issue_date_str}.parquet\")\n",
    "    utils.make_parent_dir(parquet_filepath)\n",
    "    df.to_parquet(parquet_filepath)\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    # Print out some DataFrame stats\n",
    "    # print(df.info(verbose=True, memory_usage='deep'))\n",
    "    # print(df.memory_usage(index=True, deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082cf3d-3a92-4854-b1f2-33ea8f3fb51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
