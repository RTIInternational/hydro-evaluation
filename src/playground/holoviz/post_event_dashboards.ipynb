{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f28e53-63b8-48e1-8017-0c4c85997cae",
   "metadata": {},
   "source": [
    "## TEEHR Example 2 - Explore Forecast Data from a Recent Flood Event\n",
    "\n",
    "Add more text description about this use case....\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777e449-4585-453a-be09-84e2a98645ae",
   "metadata": {},
   "source": [
    "### Install and Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a992e6-c34d-42bf-a1a6-acb6d680b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install spatialpandas colormap colorcet duckdb\n",
    "#!pip install 'teehr @ git+https://[]@github.com/RTIInternational/teehr@main'\n",
    "#!pip install 'teehr @ git+https://[]@github.com/RTIInternational/teehr@39d6627e4f49b0bdeab3a4c4e8837e6ce5a15f78'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efca43-3791-4e08-a82e-73e0b571ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.queries.duckdb as tqd\n",
    "\n",
    "# dashboard functions\n",
    "import dashboard_utils as du\n",
    "import importlib\n",
    "\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import spatialpandas as spd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from typing import List\n",
    "import duckdb as ddb\n",
    "\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews.element import tiles\n",
    "import geoviews as gv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "from holoviews.operation.datashader import rasterize, spread\n",
    "hv.extension('bokeh', logo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435147c1-0704-497d-aa10-d4a37432dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation study directory\n",
    "STUDY_DIR = Path(\"/home\", \"jovyan\", \"shared\", \"rti-eval\", \"post-event-example\")\n",
    "\n",
    "## specify general units (english or metric) to show in visualization\n",
    "viz_units = \"metric\"\n",
    "\n",
    "# evaluation scenario definitions - specific variables and configurations to be compared within the overall study\n",
    "\n",
    "# medium range streamflow forecast evaluation files \n",
    "MRF_streamflow = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"usgs\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"medium_range_mem1\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"usgs_nwm22_crosswalk.parquet\"),\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"usgs_geometry.parquet\")\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "MRF_forcing = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_analysis_assim\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_medium_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"huc10_huc10_crosswalk.parquet\"),                    # the primary and secondary are both HUC10\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"huc10_geometry.parquet\"),\n",
    ")\n",
    "\n",
    "# short range streamflow forecast evaluation files \n",
    "SRF_streamflow = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=MRF_streamflow[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "SRF_forcing = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=MRF_forcing[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "eval_scenarios = [MRF_streamflow, MRF_forcing, SRF_streamflow, SRF_forcing]\n",
    "\n",
    "attribute_paths = dict(\n",
    "    usgs_upstream_area=Path(STUDY_DIR, \"geo\", \"usgs_attr_upstream_area.parquet\"),\n",
    "    usgs_ecoregions=Path(STUDY_DIR, \"geo\", \"usgs_attr_ecoregions.parquet\"),\n",
    "    usgs_stream_order=Path(STUDY_DIR, \"geo\", \"usgs_attr_stream_order.parquet\"),\n",
    "    usgs_huc_crosswalk=Path(STUDY_DIR, \"geo\", \"usgs_huc12_crosswalk.parquet\"),\n",
    "    #nwm22_huc_crosswalk=Path(STUDY_DIR, \"geo\", \"nwm22_huc12_crosswalk.parquet\"),\n",
    "    #UPSTREAM_IMPERVIOUS = Path(STUDY_DIR, \"geo\", \"usgs_attr_upstream_imperv.parquet\")    # don't have this data yet\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa283fae-31fb-4ac4-b3ba-cc664292a389",
   "metadata": {},
   "source": [
    "## Select the scenario and date ranges\n",
    "\n",
    "Next we will check the dates available in the parquet files, and use a slider to select all or a portion of the total available period to evaluate.\n",
    "(ToDo: create utility to check that data are complete for all of the above defined timeseries files between the min/max dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619002e-0d29-43c3-a8fd-e25c74b785c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "scenarios = [MRF_streamflow, MRF_forcing]\n",
    "[value_time_slider, reference_time_slider] = du.get_filter_date_widgets(scenarios)\n",
    "pn.Column(pn.Spacer(height=10), value_time_slider, reference_time_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb0b3d-e116-4bfa-9057-1e4cefbffeae",
   "metadata": {},
   "source": [
    "## Get the streamflow data\n",
    "For an initial example, we will use a single reference time (start of slider) to explore the comparison between forecast and observed data. Later we will use this widget more interactively in a dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e62de-e11c-4fc1-9965-79bb3f151faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "\n",
    "metrics_gdf = du.run_teehr_query(\n",
    "    query_type=\"metrics\",\n",
    "    primary_filepath=scenarios[0]['primary_filepath'],\n",
    "    secondary_filepath=scenarios[0]['secondary_filepath'],\n",
    "    crosswalk_filepath=scenarios[0]['crosswalk_filepath'],\n",
    "    geometry_filepath=scenarios[0]['geometry_filepath'],\n",
    "    value_time_start=value_time_slider[1].value_start,    \n",
    "    value_time_end=value_time_slider[1].value_end,    \n",
    "    reference_time_single=reference_time_slider[1].value_start,    \n",
    "    value_min=0,    \n",
    "    include_metrics=['primary_maximum','secondary_maximum','max_value_delta'],\n",
    "    group_by=['primary_location_id','reference_time'],\n",
    "    attribute_paths=attribute_paths,\n",
    ")\n",
    "# convert units if needed\n",
    "metrics_gdf = du.convert_metrics_to_viz_units(metrics_gdf, viz_units)\n",
    "\n",
    "# display a snippet\n",
    "display(metrics_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c856bb-3977-4b95-b52d-a61edff81aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add percent difference and some useful attributes\n",
    "metrics_gdf['perc_diff'] = metrics_gdf['max_value_delta']/metrics_gdf['primary_maximum'] * 100\n",
    "attr_df = du.combine_attributes(attribute_paths,viz_units)\n",
    "metrics_gdf = du.merge_attr_to_gdf(metrics_gdf, attr_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b02641-b2f0-496f-8457-9d7ec551e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d564d-626c-49d7-9a85-116bd1db8694",
   "metadata": {},
   "source": [
    "### Create a linked visualizations using holoviews\n",
    "First a simple map showing the percent difference in peak flow across the county in this 1 forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eaca8e-6f1a-421c-bd5b-06791a3844fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure='perc_diff'\n",
    "width = 700\n",
    "basemap = osm2 = tiles.OSM()#.redim(x='easting', y='northing') #gv.tile_sources.CartoLight\n",
    "points_hv = hv.Points(df, kdims=['easting','northing'], vdims=[measure, ('secondary_maximum','fcst_peak'), ('primary_maximum','obs_peak'),('primary_location_id','gage_id')])\n",
    "points_hv.opts(width=width, height=400, color=hv.dim(measure), clim=(-100,100),\n",
    "    cmap=cc.CET_D1A[::-1], size = 5, xaxis=None, yaxis=None, colorbar=True, tools=['hover'])\n",
    "\n",
    "diff_hist = df.hvplot.hist(y=measure, width=width, bins=100, bin_range=(-100, 1000), height=200, xlabel='% Difference Peak Flow')\n",
    "diff_scat = hv.Scatter(df, kdims=['secondary_maximum'], vdims=['primary_maximum','easting','northing',measure])\n",
    "diff_scat.opts(alpha=0.2, width=400, height=400, xlabel='Forecast Peak', ylabel='Observed Peak')\n",
    "ls = hv.link_selections.instance()\n",
    "ls((basemap*points_hv + diff_scat + diff_hist)).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839da118-f36f-42aa-84a4-2969b194c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(sizing_mode='scale_both')\n",
    "metrics_gdf = metrics_gdf.to_crs(\"EPSG:3857\")\n",
    "sdf = spd.GeoDataFrame(metrics_gdf)\n",
    "title = (f\"Reference Time: {reference_time_slider[1].value_start}\")\n",
    "diff_map = sdf.hvplot.points(c='perc_diff', cmap=cc.CET_D1A[::-1], clim=(-100,100), width=800, height=400,\n",
    "                             clabel=\"% Difference Peak Flow\", title=title, size=5, xaxis = None, yaxis = None, tiles='OSM')\n",
    "diff_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37a092-72e9-431d-83de-44adfea0de7a",
   "metadata": {},
   "source": [
    "### Create other basic plots to explore the data more.... link them to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a8a6b-809b-43b4-b399-d8e51bfda31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure='perc_diff'\n",
    "width = 700\n",
    "basemap = osm2 = tiles.OSM()#.redim(x='easting', y='northing') #gv.tile_sources.CartoLight\n",
    "points_hv = hv.Points(df, kdims=['easting','northing'], vdims=[measure, ('secondary_maximum','fcst_peak'), ('primary_maximum','obs_peak'),('primary_location_id','gage_id')])\n",
    "points_hv.opts(width=width, height=400, color=hv.dim(measure), clim=(-100,100),\n",
    "    cmap=cc.CET_D1A[::-1], size = 5, xaxis=None, yaxis=None, colorbar=True, tools=['hover'])\n",
    "\n",
    "diff_hist = df.hvplot.hist(y=measure, width=width, bins=100, bin_range=(-100, 1000), height=200, xlabel='% Difference Peak Flow')\n",
    "diff_scat = hv.Scatter(df, kdims=['secondary_maximum'], vdims=['primary_maximum','easting','northing',measure])\n",
    "diff_scat.opts(alpha=0.2, width=400, height=400, xlabel='Forecast Peak', ylabel='Observed Peak')\n",
    "ls = hv.link_selections.instance()\n",
    "ls((basemap*points_hv + diff_scat + diff_hist)).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4c47d-2fd8-4065-bb09-5e87a94e3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "ts_df = du.run_teehr_query(\n",
    "    query_type=\"timeseries\",\n",
    "    primary_filepath=scenarios[0][\"primary_filepath\"],\n",
    "    secondary_filepath=scenarios[0][\"secondary_filepath\"],\n",
    "    crosswalk_filepath=scenarios[0][\"crosswalk_filepath\"],\n",
    "    geometry_filepath=scenarios[0][\"geometry_filepath\"],\n",
    "    value_time_start=value_time_slider[1].value_start,    \n",
    "    value_time_end=value_time_slider[1].value_end,    \n",
    "    reference_time_single=reference_time_slider[1].value_start,    \n",
    "    value_min=0,  \n",
    "    attribute_paths=attribute_paths,\n",
    "    return_query=False,\n",
    ")\n",
    "display(ts_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa09c7-01b2-464d-a9d9-36848bea1482",
   "metadata": {},
   "source": [
    "### Add some additional attributes and generate different plots\n",
    "\n",
    "normalize flows, add linked histogram of upstream area and/or ecoregion..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8db537-d27b-4e61-8faf-5e1bbed4cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  work on 3 way map.... add precip... add timeseries\n",
    "\n",
    "# showing off the ability to quickly generate statistics based ont he whole population with different filters, limits, groupings\n",
    "# also having the raw data right there... for time series plots\n",
    "\n",
    "pn.extension(sizing_mode='scale_both')\n",
    "prim_map = sdf.hvplot.points(c='primary_maximum', cmap=cc.CET_L8[::-1], cnorm='eq_hist', clim=(0,15000), width=400,\n",
    "                             clabel=\"Peak Flow (cfs)\", title=title, size=5, xaxis = None, yaxis = None, tiles='CartoLight')\n",
    "sec_map = sdf.hvplot.points(c='secondary_maximum', cmap=cc.CET_L8[::-1], cnorm='eq_hist', clim=(0,15000), width=400,\n",
    "                             clabel=\"Peak Flow (cfs)\", title=title, size=5, xaxis = None, yaxis = None, tiles='CartoLight')\n",
    "\n",
    "prim_map + sec_map + basemap*points_hv.opts(width=400, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea7be8-a605-422b-8813-e6b89ff1384a",
   "metadata": {},
   "source": [
    "To do:\n",
    "build up 3-col explorer layout  ...add precip... add timeseries from prior notebook   \n",
    "turn into a dashboard at end  \n",
    "try other scatter layouts, find best for alt dashboard - decide between these two for demo (prob only time for 1 post event example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004171ac-94f8-4406-b7a5-d78392a304b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tu)\n",
    "\n",
    "# metric query wrapper\n",
    "gdf = du.get_comparison_metrics(\n",
    "    primary_filepath=primary_filepath_STREAMFLOW,\n",
    "    secondary_filepath=secondary_filepath_STREAMFLOW,\n",
    "    crosswalk_filepath=crosswalk_filepath_STREAMFLOW,\n",
    "    geometry_filepath=geometry_filepath_STREAMFLOW,      \n",
    "    single_reference_time=reference_time_player.value,    \n",
    "    query_value_min=0,\n",
    ")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a76d02-480f-49bf-8f55-12758aae435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  will need another wrapper around the above to generate the holoviews element, like in prior notebooks, but with new query wrapper structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93dfb9-1b7d-4a57-8536-cf4abe9e3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  stuff below is remnants - reworking dashboards based on above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d7820-57bb-441a-ae6b-2125131a0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## add normalized flow\n",
    "# max_gdf['primary_ave_norm'] = merge_gdf['primary_maximum'] / merge_gdf['attribute_value'] * 3600 * 12\n",
    "# max_gdf['secondary_ave_norm'] = merge_gdf['secondary_maximum'] / merge_gdf['attribute_value'] * 3600 * 12\n",
    "\n",
    "# # subset data based on requested min/max (if any defined, e.g., only > 0 or other threshold)\n",
    "# if measure_min_requested:\n",
    "#     data_gdf = data_gdf[data_gdf[measure] >= measure_min_requested]\n",
    "# if measure_max_requested:\n",
    "#     data_gdf = data_gdf[data_gdf[measure] <= measure_max_requested]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee947059-ee6a-4c67-8636-f24483544a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### General plotting options\n",
    "\n",
    "flow_measure = \"max_in_hr\"\n",
    "flow_map_title = \"Normalized Event Peak Flow (in/hr)\"  \n",
    "precip_map_title = \"Total Precipitation (in)\"\n",
    "\n",
    "if flow_measure == \"max_recurr_int\":\n",
    "    points_cmap_opts = dict(cmap=dbs.get_recurr_colormap(), legend_position='bottom_right')\n",
    "else:\n",
    "    points_cmap_opts = dict(cmap=cc.CET_L8[::-1], cnorm='eq_hist', colorbar=True) \n",
    "    \n",
    "map_opts = dict(show_grid=False, xaxis = None, yaxis = None)\n",
    "curve_opts = dict(toolbar = None, tools=[\"hover\"], show_title = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1fb58-3dc4-4d34-bb53-6ecc946a1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Build components for the dashboard\n",
    "\n",
    "# Build background (static) map Elements - background tiles and all gage points \n",
    "# for reference on rasterized catchments DynamicMap\n",
    "tiles_background = gv.tile_sources.CartoLight.opts(**map_opts, toolbar = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66351ca1-96af-4567-b3da-542bd7b18335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#points_background \n",
    "# points_background = hv.Points(points_gdf, kdims = ['easting','northing'], vdims = ['id']).opts(color='lightgray', size=2, toolbar='right')\n",
    "# points = spread(rasterize(points_background), px=4, shape='circle').opts(cmap=[\"lightgray\"]) #, responsive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea85035-2b30-404c-8019-184e5f222da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(sizing_mode='stretch_width')\n",
    "\n",
    "layout = pn.Column(\n",
    "    pn.Column(current_ref_time, reference_time_player),\n",
    "    #pn.Row(pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0)),\n",
    "    #pn.Row(pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0)),\n",
    "    pn.Row(pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0)),\n",
    "    pn.Row(pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0)),\n",
    "    pn.Spacer(background='green', height=150, margin=0),\n",
    "    pn.Spacer(background='red', height=150, margin=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039a299-8a0c-4d8f-9c7d-9b1cc069cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gspec = pn.GridSpec(sizing_mode='stretch_width', width_policy='max', height=900)\n",
    "\n",
    "# gspec[0,:] = pn.Column(current_ref_time, reference_time_player, margin=5)\n",
    "# gspec[1:4,0] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[1:4,1] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[1:4,2] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[4:7,0] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[4:7,1] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[4:7,2] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[7,:] = pn.Spacer(background='green',  margin=0)\n",
    "# gspec[8,:] = pn.Spacer(background='red',  margin=0)\n",
    "\n",
    "# gspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ace93-6fc0-4de6-9409-4459b63f1aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f367d-4a0d-4c61-8480-03fb433ea594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c8158-4cd8-4608-8d1b-4707953210ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32ff88-7e76-434b-84b1-468b93c64aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
