{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f28e53-63b8-48e1-8017-0c4c85997cae",
   "metadata": {},
   "source": [
    "## TEEHR Example 2 - Explore Forecast Data from a Recent Flood Event\n",
    "\n",
    "Add more text description about this use case....\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777e449-4585-453a-be09-84e2a98645ae",
   "metadata": {},
   "source": [
    "### Install and Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a992e6-c34d-42bf-a1a6-acb6d680b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install spatialpandas colormap colorcet duckdb\n",
    "#!pip install 'teehr @ git+https://[]@github.com/RTIInternational/teehr@main'\n",
    "#!pip install 'teehr @ git+https://[]@github.com/RTIInternational/teehr@39d6627e4f49b0bdeab3a4c4e8837e6ce5a15f78'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378df2c-58f2-416a-a8b8-bb74c2e90a90",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install 'teehr @ git+https://4@github.com/RTIInternational/teehr@main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efca43-3791-4e08-a82e-73e0b571ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.queries.duckdb as tqd\n",
    "import teehr.queries.utils as tqu\n",
    "import dashboard_utils as du\n",
    "\n",
    "import importlib\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import spatialpandas as spd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from typing import List\n",
    "import duckdb as ddb\n",
    "\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews.element import tiles\n",
    "import geoviews as gv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "\n",
    "from holoviews.operation.datashader import rasterize, spread\n",
    "hv.extension('bokeh', logo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435147c1-0704-497d-aa10-d4a37432dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation study directory\n",
    "STUDY_DIR = Path(\"/home\", \"jovyan\", \"shared\", \"rti-eval\", \"post-event-example\")\n",
    "\n",
    "## specify general units (english or metric) to show in visualization\n",
    "viz_units = \"metric\"\n",
    "\n",
    "# evaluation scenario definitions - specific variables and configurations to be compared within the overall study\n",
    "\n",
    "# medium range streamflow forecast evaluation files \n",
    "MRF_streamflow = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"usgs\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"medium_range_mem1\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"usgs_nwm22_crosswalk.parquet\"),\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"usgs_geometry.parquet\")\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "MRF_forcing = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_analysis_assim\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_medium_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"huc10_huc10_crosswalk.parquet\"),                    # the primary and secondary are both HUC10\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"huc10_geometry.parquet\"),\n",
    ")\n",
    "\n",
    "# short range streamflow forecast evaluation files \n",
    "SRF_streamflow = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=MRF_streamflow[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "SRF_forcing = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=MRF_forcing[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "eval_scenarios = [MRF_streamflow, MRF_forcing, SRF_streamflow, SRF_forcing]\n",
    "\n",
    "attribute_paths = dict(\n",
    "    usgs_upstream_area=Path(STUDY_DIR, \"geo\", \"usgs_attr_upstream_area.parquet\"),\n",
    "    usgs_ecoregions=Path(STUDY_DIR, \"geo\", \"usgs_attr_ecoregions.parquet\"),\n",
    "    usgs_stream_order=Path(STUDY_DIR, \"geo\", \"usgs_attr_stream_order.parquet\"),\n",
    "    usgs_huc_crosswalk=Path(STUDY_DIR, \"geo\", \"usgs_huc12_crosswalk.parquet\"),\n",
    "    #nwm22_huc_crosswalk=Path(STUDY_DIR, \"geo\", \"nwm22_huc12_crosswalk.parquet\"),\n",
    "    #UPSTREAM_IMPERVIOUS = Path(STUDY_DIR, \"geo\", \"usgs_attr_upstream_imperv.parquet\")    # don't have this data yet\n",
    ")\n",
    "attribute_df = du.combine_attributes(attribute_paths,viz_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa283fae-31fb-4ac4-b3ba-cc664292a389",
   "metadata": {},
   "source": [
    "## Select the scenario and date ranges before launching the dashboard\n",
    "\n",
    "Next we will check the dates available in the parquet files, and use a slider to select all or a portion of the total available period to evaluate.\n",
    "(ToDo: create utility to check that data are complete for all of the above defined timeseries files between the min/max dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176949f-84c4-4aa2-b7c2-ae26ea7f19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "scenario_selector = du.get_scenario_selector(scenario_name_list=sorted(du.get_scenario_names(eval_scenarios)))  \n",
    "value_time_slider = du.get_value_time_slider(scenarios)\n",
    "pn.Column(pn.Spacer(height=10),\n",
    "          pn.Row(pn.panel(scenario_selector, width = 80), pn.Spacer(width=20), value_time_slider)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb0b3d-e116-4bfa-9057-1e4cefbffeae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explore forecasts, one at a time\n",
    "For an initial example, we will visualize a single reference time at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca054492-e26e-43e1-9103-0f2a662891e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "\n",
    "streamflow_scenario = MRF_streamflow\n",
    "precip_scenario = MRF_forcing\n",
    "\n",
    "######### Build components for the dashboard\n",
    "\n",
    "huc2_selector = du.get_huc2_selector()\n",
    "\n",
    "# reference time player (eventually replace with individual arrows)\n",
    "start_date = value_time_slider[1].value_start-timedelta(hours=1)\n",
    "end_date = value_time_slider[1].value_end\n",
    "reference_time_player = du.get_reference_time_player_selected_dates(scenario=scenarios, start=start_date, end=end_date)\n",
    "reftime_player_header = pn.pane.HTML(\"Use the slider or forward arrow (with line) to select a reference time:\", \n",
    "                                     style={'font-size': '16px', 'font-weight': 'bold'})\n",
    "current_ref_time = pn.bind(du.get_reference_time_text, reference_time=reference_time_player.param.value)\n",
    "\n",
    "# Build background (static) map Elements - background tiles and all gage points \n",
    "# for reference on rasterized catchments DynamicMap\n",
    "tiles_background = gv.tile_sources.CartoLight #OSM\n",
    "points_background = du.get_all_points(streamflow_scenario)\n",
    "\n",
    "# bind points dataframe to widgets\n",
    "points_bind = pn.bind(\n",
    "    du.build_hv_points_from_query,\n",
    "    scenario = MRF_streamflow,\n",
    "    value_time_start=value_time_slider[1].param.value_start,\n",
    "    value_time_end=value_time_slider[1].param.value_end,\n",
    "    reference_time_single=reference_time_player.param.value,\n",
    "    value_min=0,   \n",
    "    group_by=['primary_location_id','reference_time'],    \n",
    "    include_metrics=['primary_maximum','secondary_maximum','max_value_delta'],    \n",
    "    metric_limits=dict(primary_maximum=(0.1, 10e6)),\n",
    "    attribute_paths=attribute_paths,\n",
    "    units=viz_units,\n",
    ")\n",
    "# precip_tsplot_bind = pn.bind(\n",
    "#     du.build_hv_precip_tsplot_from_query,\n",
    "#     scenario = MRF_streamflow,\n",
    "#     value_time_start=value_time_slider[1].param.value_start,\n",
    "#     value_time_end=value_time_slider[1].param.value_end,\n",
    "#     reference_time_single=reference_time_player.param.value,\n",
    "#     value_min=0,   \n",
    "#     group_by=['primary_location_id','reference_time'],    \n",
    "#     include_metrics=['primary_maximum','secondary_maximum','max_value_delta'],    \n",
    "#     metric_limits=dict(primary_maximum=(0.1, 10e6)),\n",
    "#     attribute_paths=attribute_paths,\n",
    "#     units=viz_units,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "points_dmap = hv.DynamicMap(points_bind)\n",
    "\n",
    "# Define stream source as points selection from points_dmap\n",
    "point_selection = hv.streams.Selection1D(source=points_dmap, index=[0])\n",
    "\n",
    "######### Common plotting options\n",
    "\n",
    "map_opts = dict(show_grid=False, show_legend=False, xaxis = None, yaxis = None, width=600, height=400)\n",
    "points_cmap_opts = dict(cmap=cc.CET_L8[::-1], cnorm='eq_hist', colorbar=True) \n",
    "curve_opts = dict(toolbar = None, tools=[\"hover\"], show_title = False, width=1050)\n",
    "\n",
    "###### Apply style options that vary by element\n",
    "\n",
    "aggregator = pn.bind(du.get_aggregator, \"primary_sum\")\n",
    "tiles_background.opts(**map_opts)\n",
    "points_background.opts(**map_opts, color='lightgray', size=2, toolbar = 'right')\n",
    "points_dmap.opts(**map_opts, tools=['hover','tap'], color=hv.dim('max_perc_diff'), \n",
    "                 cmap=cc.CET_D1A[::-1], cnorm='linear', clim=(-100,100), colorbar=True,\n",
    "                 size=5, toolbar='above', title=\"Peak Error (%)\",\n",
    "                 selection_line_width=5, nonselection_line_width=0, nonselection_alpha=0.1)\n",
    "\n",
    "###### Panel header\n",
    "\n",
    "header = pn.Row(\n",
    "            pn.pane.PNG('https://ciroh.ua.edu/wp-content/uploads/2022/08/CIROHLogo_200x200.png', width=60),\n",
    "            pn.pane.Markdown(\n",
    "                \"\"\"\n",
    "                ## CIROH Tools for Exploratory Evaluation in Hydrology Research (TEEHR):  Example 1 - Forecast Data Exploration\n",
    "                \"\"\",\n",
    "                width_policy=\"max\", sizing_mode=\"stretch_width\"\n",
    "            )\n",
    ")\n",
    "# Build the Panel layout\n",
    "layout = \\\n",
    "    pn.Column(\n",
    "        pn.Spacer(height=10), header, reftime_player_header,\n",
    "        pn.Row(\n",
    "            pn.Column(current_ref_time, reference_time_player),\n",
    "            pn.Spacer(width=50), huc2_selector),\n",
    "        pn.Row(tiles_background*points_dmap)\n",
    ")\n",
    "# launch the layout\n",
    "layout.servable()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf5191-7014-4f54-aa8a-e66ae994bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "precip_plot_hv = du.build_hv_precip_tsplot_from_query_selected_point(\n",
    "        index=selection_stream.index,\n",
    "        points_dmap = points_dmap,          \n",
    "        scenario = MRF_forcing,\n",
    "        reference_time_single=reference_time_player.value,\n",
    "        value_min=0,     \n",
    "        attribute_paths=attribute_paths,\n",
    "        units=viz_units,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4497067-ea37-41d6-8855-90d039b6b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=point_selection.index,\n",
    "if len(index) > 0 and len(points_dmap.dimensions('value')) > 0:  \n",
    "    point_id = points_dmap.dimension_values('primary_location_id')[index][0]\n",
    "    cross = pd.read_parquet(attribute_paths['usgs_huc_crosswalk'])\n",
    "    huc12_id = cross.loc[cross['primary_location_id']==point_id, 'secondary_location_id'].iloc[0]\n",
    "    huc10_id = \"-\".join(['huc10', huc12_id.split(\"-\")[1][:10]])\n",
    "    title = f\"{huc10_id} (Contains Gage: {point_id})\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4beef3-3868-422f-bc10-dd5ff6639129",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "df = du.run_teehr_query(\n",
    "    query_type=\"timeseries\",\n",
    "    scenario = MRF_forcing,\n",
    "    location_id=huc10_id,\n",
    "    reference_time_single=reference_time_player.value,\n",
    "    value_min=0,\n",
    "    order_by=['primary_location_id','reference_time','value_time'],\n",
    "    attribute_paths=attribute_paths,\n",
    "    include_geometry=False,\n",
    ")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db312139-50f5-4fa0-b8a0-ce16043e724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd06c32-64f8-4f6c-9874-ff6e96424269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time stuff\n",
    "units='metric'\n",
    "opts = dict(curve_opts, xaxis = None, height=150)\n",
    "\n",
    "df['value_time_str'] = df['value_time'].dt.strftime('%Y-%m-%d-%H')\n",
    "time_start = df['value_time'].min()\n",
    "time_end = df['value_time'].max()\n",
    "        \n",
    "t = time_start + (time_end - time_start)*0.01\n",
    "text_x = t.replace(second=0, microsecond=0, minute=0).strftime('%Y-%m-%d-%H')\n",
    "\n",
    "\n",
    "if units == 'metric':\n",
    "    unit_rate_label = 'mm/hr'\n",
    "    unit_cum_label = 'mm'\n",
    "else:\n",
    "    unit_rate_label = 'in/hr'\n",
    "    unit_cum_label = 'in'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce347d8-f170-4502-abd5-a322b2617272",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "if 'value' in df.columns:  #single timeseries\n",
    "    df['cumulative'] = df['value'].cumsum()\n",
    "    \n",
    "    data_max = df['primary_value'].max()\n",
    "    ymax_bars = max(data_max*1.1,1)\n",
    "    ymax_curve = max(data_max*1.1,1)\n",
    "    text_y = ymax_bars*0.9   \n",
    "    \n",
    "    bars = hv.Bars(df, kdims = [('value_time_str','Date')], vdims = [('value', 'Precip Rate ' + unit_rate_label)])\n",
    "    curve = hv.Curve(df, kdims = [('value_time_str', 'Date')], vdims = [('cum', 'Precip ' + unit_cum_label)])\n",
    "    \n",
    "    bars.opts(**opts, fill_color = 'blue', line_color = None, ylim=(0, ymax_bars))\n",
    "    curve.opts(**opts, color='orange', hooks=[du.plot_secondary_bars_curve])\n",
    "    \n",
    "else:\n",
    "    \n",
    "    df['primary_cumulative'] = df['primary_value'].cumsum()\n",
    "    df['secondary_cumulative'] = df['secondary_value'].cumsum()\n",
    "    data_max = max(df['primary_value'].max(), df['secondary_value'].max())\n",
    "    ymax_bars = max(data_max*1.1,1)\n",
    "    ymax_curve = max(data_max*1.1,1)\n",
    "    text_y = ymax_bars*0.9   \n",
    "    \n",
    "    bars_prim = hv.Bars(df, kdims = [('value_time_str','Date')], vdims = [('primary_value', 'Precip Rate ' + unit_rate_label)])\n",
    "    curve_prim = hv.Curve(df, kdims = [('value_time_str', 'Date')], vdims = [('primary_cumulative', 'Precip ' + unit_cum_label)])\n",
    "    bars_sec = hv.Bars(df, kdims = [('value_time_str','Date')], vdims = [('secondary_value', 'Precip Rate ' + unit_rate_label)])\n",
    "    curve_sec = hv.Curve(df, kdims = [('value_time_str', 'Date')], vdims = [('secondary_cumulative', 'Precip ' + unit_cum_label)])\n",
    "    \n",
    "    bars_prim.opts(**opts, fill_color = 'blue', line_color = None, ylim=(0, ymax_bars))\n",
    "    curve_prim.opts(**opts, color='orange', hooks=[du.plot_secondary_bars_curve])    \n",
    "    bars_sec.opts(**opts, fill_color = 'blue', line_color = None, ylim=(0, ymax_bars))\n",
    "    curve_sec.opts(**opts, color='orange', hooks=[du.plot_secondary_bars_curve])      \n",
    "    \n",
    "text = hv.Text(text_x, text_y, title).opts(text_align='left', text_font_size='10pt', \n",
    "                                           text_color='#57504d', text_font_style='bold')    \n",
    "\n",
    "ts_layout_hv = (bars_prim * curve_prim * text).opts(show_title=False)\n",
    "#ts_layout_hv = (bars_prim * text).opts(show_title=False)\n",
    "ts_layout_hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67959f54-7ad6-4774-a3af-a5c349bec3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_test2 = hv.Bars(df, kdims = [('value_time_str','Date')], vdims = [('primary_value', 'Precip Rate ' + unit_rate_label)])\n",
    "curve_test2 = hv.Curve(df, kdims = [('value_time_str', 'Date')], vdims = [('primary_cumulative', 'Precip ' + unit_cum_label)])\n",
    "\n",
    "bars_test2.opts(**opts, fill_color = 'blue', line_color = None, ylim=(0, ymax_bars))\n",
    "curve_test2.opts(**opts, color='orange', hooks=[du.plot_secondary_bars_curve])  \n",
    "\n",
    "bars_test2 * curve_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2d7e5-abcd-4c43-aeba-0ccf88ce30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_test = hv.Curve(df, kdims = [('value_time_str', 'Date')], vdims = [('primary_cumulative', 'Precip ' + unit_cum_label)])\n",
    "curve_test.opts(color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d106f2-c947-40c9-87bd-cc67f0587aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_test.opts(color='orange', hooks=[du.plot_secondary_bars_curve])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8acfed-e201-4bc1-bdae-26cf323c3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_prim.opts(**opts, fill_color = 'blue', line_color = None, ylim=(0, ymax_bars))\n",
    "curve_prim.opts(**opts, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f9f4e-bdb7-4ce1-8ca0-cae6d90b8f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9117d52-94d5-47e7-a536-adeae4c836bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primary_cumulative'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea46a5-9516-49e3-94b1-484bcbf68802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b021a-e2c1-4d38-96df-158a7ede2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_secondary_bars_curve(plot, element):\n",
    "    \"\"\"\n",
    "    Hook to plot data on a secondary (twin) axis on a Holoviews Plot with Bokeh backend.\n",
    "    More info:\n",
    "    - http://holoviews.org/user_guide/Customizing_Plots.html#plot-hooks\n",
    "    - https://docs.bokeh.org/en/latest/docs/user_guide/plotting.html#twin-axes\n",
    "    \"\"\"\n",
    "    fig: Figure = plot.state\n",
    "    glyph_first: GlyphRenderer = fig.renderers[0]  # will be the original plot\n",
    "    glyph_last: GlyphRenderer = fig.renderers[-1] # will be the new plot\n",
    "    right_axis_name = \"twiny\"\n",
    "    # Create both axes if right axis does not exist\n",
    "    if right_axis_name not in fig.extra_y_ranges.keys():\n",
    "        # Recreate primary axis (left)\n",
    "        y_first_name = glyph_first.glyph.top\n",
    "        y_first_min = glyph_first.data_source.data[y_first_name].min()\n",
    "        y_first_max = glyph_first.data_source.data[y_first_name].max()\n",
    "        y_first_offset = (y_first_max - y_first_min) * 0.1\n",
    "        fig.y_range = Range1d(\n",
    "            start=0,\n",
    "            end=max(y_first_max,1) + y_first_offset\n",
    "       )\n",
    "        fig.y_range.name = glyph_first.y_range_name\n",
    "        # Create secondary axis (right)\n",
    "        y_last_name = glyph_last.glyph.y\n",
    "        y_last_min = glyph_last.data_source.data[y_last_name].min()\n",
    "        y_last_max = glyph_last.data_source.data[y_last_name].max()\n",
    "        y_last_offset = (y_last_max - y_last_min) * 0.1\n",
    "        fig.extra_y_ranges = {right_axis_name: Range1d(\n",
    "            start=0,\n",
    "            end=max(y_last_max,1) + y_last_offset\n",
    "        )}\n",
    "        fig.add_layout(LinearAxis(y_range_name=right_axis_name, axis_label=glyph_last.glyph.y), \"right\")\n",
    "    # Set right axis for the last glyph added to the figure\n",
    "    glyph_last.y_range_name = right_axis_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0ddb3-a7f6-4b6d-8b3b-cb79126a6e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_layout_hv = (bars_prim * curve_prim * text).opts(show_title=False)\n",
    "ts_layout_hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f673ad2-0f12-4e34-81bf-7e94e80224c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37545ff0-6b30-45db-acf8-c9b33fef10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_dmap.dimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d564d-626c-49d7-9a85-116bd1db8694",
   "metadata": {},
   "source": [
    "### Create a linked visualizations using holoviews\n",
    "First a simple map showing the percent difference in peak flow across the county in this 1 forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eaca8e-6f1a-421c-bd5b-06791a3844fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure='perc_diff'\n",
    "width = 700\n",
    "basemap = osm2 = tiles.OSM()#.redim(x='easting', y='northing') #gv.tile_sources.CartoLight\n",
    "points_hv = hv.Points(df, kdims=['easting','northing'], vdims=[measure, ('secondary_maximum','fcst_peak'), ('primary_maximum','obs_peak'),('primary_location_id','gage_id')])\n",
    "points_hv.opts(width=width, height=400, color=hv.dim(measure), clim=(-100,100),\n",
    "    cmap=cc.CET_D1A[::-1], size = 5, xaxis=None, yaxis=None, colorbar=True, tools=['hover'])\n",
    "\n",
    "diff_hist = df.hvplot.hist(y=measure, width=width, bins=100, bin_range=(-100, 1000), height=200, xlabel='% Difference Peak Flow')\n",
    "diff_scat = hv.Scatter(df, kdims=['secondary_maximum'], vdims=['primary_maximum','easting','northing',measure])\n",
    "diff_scat.opts(alpha=0.2, width=400, height=400, xlabel='Forecast Peak', ylabel='Observed Peak')\n",
    "ls = hv.link_selections.instance()\n",
    "ls((basemap*points_hv + diff_scat + diff_hist)).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839da118-f36f-42aa-84a4-2969b194c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(sizing_mode='scale_both')\n",
    "metrics_gdf = metrics_gdf.to_crs(\"EPSG:3857\")\n",
    "sdf = spd.GeoDataFrame(metrics_gdf)\n",
    "title = (f\"Reference Time: {reference_time_slider[1].value_start}\")\n",
    "diff_map = sdf.hvplot.points(c='perc_diff', cmap=cc.CET_D1A[::-1], clim=(-100,100), width=800, height=400,\n",
    "                             clabel=\"% Difference Peak Flow\", title=title, size=5, xaxis = None, yaxis = None, tiles='OSM')\n",
    "diff_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37a092-72e9-431d-83de-44adfea0de7a",
   "metadata": {},
   "source": [
    "### Create other basic plots to explore the data more.... link them to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a8a6b-809b-43b4-b399-d8e51bfda31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure='perc_diff'\n",
    "width = 700\n",
    "basemap = osm2 = tiles.OSM()#.redim(x='easting', y='northing') #gv.tile_sources.CartoLight\n",
    "points_hv = hv.Points(df, kdims=['easting','northing'], vdims=[measure, ('secondary_maximum','fcst_peak'), ('primary_maximum','obs_peak'),('primary_location_id','gage_id')])\n",
    "points_hv.opts(width=width, height=400, color=hv.dim(measure), clim=(-100,100),\n",
    "    cmap=cc.CET_D1A[::-1], size = 5, xaxis=None, yaxis=None, colorbar=True, tools=['hover'])\n",
    "\n",
    "diff_hist = df.hvplot.hist(y=measure, width=width, bins=100, bin_range=(-100, 1000), height=200, xlabel='% Difference Peak Flow')\n",
    "diff_scat = hv.Scatter(df, kdims=['secondary_maximum'], vdims=['primary_maximum','easting','northing',measure])\n",
    "diff_scat.opts(alpha=0.2, width=400, height=400, xlabel='Forecast Peak', ylabel='Observed Peak')\n",
    "ls = hv.link_selections.instance()\n",
    "ls((basemap*points_hv + diff_scat + diff_hist)).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4c47d-2fd8-4065-bb09-5e87a94e3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "ts_df = du.run_teehr_query(\n",
    "    query_type=\"timeseries\",\n",
    "    primary_filepath=scenarios[0][\"primary_filepath\"],\n",
    "    secondary_filepath=scenarios[0][\"secondary_filepath\"],\n",
    "    crosswalk_filepath=scenarios[0][\"crosswalk_filepath\"],\n",
    "    geometry_filepath=scenarios[0][\"geometry_filepath\"],\n",
    "    value_time_start=value_time_slider[1].value_start,    \n",
    "    value_time_end=value_time_slider[1].value_end,    \n",
    "    reference_time_single=reference_time_slider[1].value_start,    \n",
    "    value_min=0,  \n",
    "    attribute_paths=attribute_paths,\n",
    "    return_query=False,\n",
    ")\n",
    "display(ts_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa09c7-01b2-464d-a9d9-36848bea1482",
   "metadata": {},
   "source": [
    "### Add some additional attributes and generate different plots\n",
    "\n",
    "normalize flows, add linked histogram of upstream area and/or ecoregion..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8db537-d27b-4e61-8faf-5e1bbed4cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  work on 3 way map.... add precip... add timeseries\n",
    "\n",
    "# showing off the ability to quickly generate statistics based ont he whole population with different filters, limits, groupings\n",
    "# also having the raw data right there... for time series plots\n",
    "\n",
    "pn.extension(sizing_mode='scale_both')\n",
    "prim_map = sdf.hvplot.points(c='primary_maximum', cmap=cc.CET_L8[::-1], cnorm='eq_hist', clim=(0,15000), width=400,\n",
    "                             clabel=\"Peak Flow (cfs)\", title=title, size=5, xaxis = None, yaxis = None, tiles='CartoLight')\n",
    "sec_map = sdf.hvplot.points(c='secondary_maximum', cmap=cc.CET_L8[::-1], cnorm='eq_hist', clim=(0,15000), width=400,\n",
    "                             clabel=\"Peak Flow (cfs)\", title=title, size=5, xaxis = None, yaxis = None, tiles='CartoLight')\n",
    "\n",
    "prim_map + sec_map + basemap*points_hv.opts(width=400, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea7be8-a605-422b-8813-e6b89ff1384a",
   "metadata": {},
   "source": [
    "To do:\n",
    "build up 3-col explorer layout  ...add precip... add timeseries from prior notebook   \n",
    "turn into a dashboard at end  \n",
    "try other scatter layouts, find best for alt dashboard - decide between these two for demo (prob only time for 1 post event example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea85035-2b30-404c-8019-184e5f222da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(sizing_mode='stretch_width')\n",
    "\n",
    "layout = pn.Column(\n",
    "    pn.Column(current_ref_time, reference_time_player),\n",
    "    #pn.Row(pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0)),\n",
    "    #pn.Row(pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0)),\n",
    "    pn.Row(pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0)),\n",
    "    pn.Row(pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0)),\n",
    "    pn.Spacer(background='green', height=150, margin=0),\n",
    "    pn.Spacer(background='red', height=150, margin=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ace93-6fc0-4de6-9409-4459b63f1aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f367d-4a0d-4c61-8480-03fb433ea594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c8158-4cd8-4608-8d1b-4707953210ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32ff88-7e76-434b-84b1-468b93c64aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
