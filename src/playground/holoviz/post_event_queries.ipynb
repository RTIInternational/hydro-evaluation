{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f28e53-63b8-48e1-8017-0c4c85997cae",
   "metadata": {},
   "source": [
    "## Example 1 - Querying the Data\n",
    "\n",
    "Add more text description about this ....\n",
    "\n",
    "First we will introduce the TEEHR query system so you get a sense of what is going on behind the scenes of the visualizations in later examples\n",
    "\n",
    ".... brief explanation,   \n",
    "concise/rapid approach to subset the timeseries you want to evaluate and get either the raw data or summary/comparison metrics  \n",
    "efficient, enables querying the data 'on the fly' within interactive visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777e449-4585-453a-be09-84e2a98645ae",
   "metadata": {},
   "source": [
    "### Install and Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a992e6-c34d-42bf-a1a6-acb6d680b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install spatialpandas colormap colorcet duckdb\n",
    "#!pip install 'teehr @ git+https://[]@github.com/RTIInternational/teehr@main'\n",
    "#!pip install 'teehr @ git+https://[]@github.com/RTIInternational/teehr@39d6627e4f49b0bdeab3a4c4e8837e6ce5a15f78'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efca43-3791-4e08-a82e-73e0b571ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.queries.duckdb as tqd\n",
    "\n",
    "# dashboard functions\n",
    "import dashboard_utils as du\n",
    "import importlib\n",
    "\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import spatialpandas as spd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from typing import List\n",
    "import duckdb as ddb\n",
    "\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews.element import tiles\n",
    "import geoviews as gv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "from holoviews.operation.datashader import rasterize, spread\n",
    "hv.extension('bokeh', logo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a32d2-6427-4a14-8b73-5384d814dbf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Point to the data that will be used for the evaluation\n",
    "\n",
    "..Note this stuff could eventually be stored in a separate configuration file\n",
    "\n",
    "..Note that assuming the cache has been generated already, not focusing on that aspect (teehr package will include examples and instructions)...\n",
    "\n",
    "These are the evaluation scenario definitions - specific variables and configurations to be compared within the overall study.\n",
    "We need to specify all the parquet files containing the data we want to evaluate, as well as some necessary associated data (geometry, crosswalks, and attributes).\n",
    "These files dictate the specific study (directory name), forecast configuration, and source of verifying data used in this evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435147c1-0704-497d-aa10-d4a37432dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall study directory\n",
    "STUDY_DIR = Path(\"/home\", \"jovyan\", \"shared\", \"rti-eval\", \"post-event-example\")\n",
    "\n",
    "# medium range streamflow forecast evaluation files \n",
    "MRF_streamflow = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"usgs\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"medium_range_mem1\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"usgs_nwm22_crosswalk.parquet\"),\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"usgs_geometry.parquet\")\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "MRF_forcing = dict(\n",
    "    scenario_name=\"medium_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_analysis_assim\", \"*.parquet\"),\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_medium_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=Path(STUDY_DIR, \"geo\", \"huc10_huc10_crosswalk.parquet\"),                    # the primary and secondary are both HUC10\n",
    "    geometry_filepath=Path(STUDY_DIR, \"geo\", \"huc10_geometry.parquet\"),\n",
    ")\n",
    "\n",
    "# short range streamflow forecast evaluation files \n",
    "SRF_streamflow = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"streamflow\",\n",
    "    primary_filepath=MRF_streamflow[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "# medium range precip forecast evaluation files\n",
    "SRF_forcing = dict(\n",
    "    scenario_name=\"short_range\",\n",
    "    variable=\"precipitation\",    \n",
    "    primary_filepath=MRF_forcing[\"primary_filepath\"],\n",
    "    secondary_filepath=Path(STUDY_DIR, \"timeseries\", \"forcing_short_range\", \"*.parquet\"),\n",
    "    crosswalk_filepath=MRF_streamflow[\"crosswalk_filepath\"],\n",
    "    geometry_filepath=MRF_streamflow[\"geometry_filepath\"],\n",
    ")\n",
    "\n",
    "eval_scenarios = [MRF_streamflow, MRF_forcing, SRF_streamflow, SRF_forcing]\n",
    "\n",
    "attribute_paths = dict(\n",
    "    usgs_upstream_area=Path(STUDY_DIR, \"geo\", \"usgs_attr_upstream_area.parquet\"),\n",
    "    usgs_ecoregions=Path(STUDY_DIR, \"geo\", \"usgs_attr_ecoregions.parquet\"),\n",
    "    usgs_stream_order=Path(STUDY_DIR, \"geo\", \"usgs_attr_stream_order.parquet\"),\n",
    "    usgs_huc_crosswalk=Path(STUDY_DIR, \"geo\", \"usgs_huc12_crosswalk.parquet\"),\n",
    "    nwm22_huc_crosswalk=Path(STUDY_DIR, \"geo\", \"nwm22_huc12_crosswalk.parquet\"),\n",
    "    #UPSTREAM_IMPERVIOUS = Path(STUDY_DIR, \"geo\", \"usgs_attr_upstream_imperv.parquet\")    # don't have this data yet\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbf293-7bd5-416f-abde-ed4633353340",
   "metadata": {},
   "source": [
    "## Select the scenario and variable for evaluation:\n",
    "We will use some panel widgets to make this easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1acd6-2abb-4a90-b22c-af9e0084eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "scenario_selector = du.get_scenario_selector(scenario_name_list=sorted(du.get_scenario_names(eval_scenarios)))  \n",
    "variable_selector = du.get_variable_selector(variable_list=du.get_scenario_variables(eval_scenarios))   \n",
    "pn.Row(scenario_selector, variable_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156accfc-8448-4a90-8b5a-b22a68864dcf",
   "metadata": {},
   "source": [
    "## Filter the data to the region, time period, stream size, threshold (etc.) of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619002e-0d29-43c3-a8fd-e25c74b785c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_2 = \"Filter the data to the subset of interest:\"\n",
    "instructions_3 = \"Run the query in the cell below, then experiment with the selections to see how results and execution times change\"\n",
    "\n",
    "importlib.reload(du)\n",
    "scenario = du.get_scenario(eval_scenarios, scenario_selector.value, variable_selector.value)\n",
    "\n",
    "value_time_slider = du.get_date_range_slider_with_range_as_title(\n",
    "    pathlist=[scenario[\"primary_filepath\"], scenario[\"secondary_filepath\"]],\n",
    "    date_type='value_time', \n",
    "    opts = dict(width = 700, bar_color = \"green\", step=3600000)\n",
    ")\n",
    "reference_time_slider = du.get_date_range_slider_with_range_as_title(\n",
    "    pathlist=[scenario[\"primary_filepath\"], scenario[\"secondary_filepath\"]],\n",
    "    date_type='reference_time',\n",
    "    opts = dict(width = 700, bar_color = \"red\", step=3600000*6))\n",
    "\n",
    "lead_time_selector = du.get_lead_time_selector()\n",
    "\n",
    "huc2_selector = du.get_huc2_selector()\n",
    "order_limit_selector = du.get_order_limit_selector()\n",
    "threshold_selector = du.get_threshold_selector(variable_selector.value)\n",
    "metric_selector = du.get_metric_selector(variable_selector.value)\n",
    "\n",
    "## tried this, did not work well - could not get the out (display(gdf)) to show up BELOW the widgets rather than above\n",
    "#query_button = pn.widgets.Button(name='Run TEEHR Query', button_type='primary')    \n",
    "#query_button.on_click(button_callback)\n",
    "\n",
    "pn.Row(\n",
    "    pn.Column(huc2_selector, order_limit_selector, threshold_selector, metric_selector),\n",
    "    pn.Spacer(width=50),    \n",
    "    pn.Column(     \n",
    "        pn.Spacer(height=10), value_time_slider,\n",
    "        pn.Spacer(height=10), reference_time_slider,\n",
    "        pn.Spacer(height=5), lead_time_selector,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe8b45-a1f9-4aeb-b9ac-1152ea30ec45",
   "metadata": {},
   "source": [
    "## Make selections above and run the query in the cell below\n",
    "### Experiment with the filter selections..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e62de-e11c-4fc1-9965-79bb3f151faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "importlib.reload(du)\n",
    "metrics_gdf = du.run_teehr_query(\n",
    "    query_type=\"metrics\",\n",
    "    scenario=scenario,\n",
    "    huc_id=huc2_selector.value,\n",
    "    order_limit=order_limit_selector.value,\n",
    "    value_time_start=value_time_slider[1].value_start,    \n",
    "    value_time_end=value_time_slider[1].value_end,    \n",
    "    reference_time_start=reference_time_slider[1].value_start,    \n",
    "    reference_time_end=reference_time_slider[1].value_end,\n",
    "    value_min=threshold_selector.value,    \n",
    "    include_metrics=metric_selector.value,\n",
    "    attribute_paths=attribute_paths,\n",
    "    return_query=False,\n",
    ")\n",
    "display(metrics_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f367d-4a0d-4c61-8480-03fb433ea594",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(du)\n",
    "ts_df = du.run_teehr_query(\n",
    "    query_type=\"timeseries\",\n",
    "    scenario=scenario,\n",
    "    huc_id=huc2_selector.value,\n",
    "    order_limit=order_limit_selector.value,\n",
    "    value_time_start=value_time_slider[1].value_start,    \n",
    "    value_time_end=value_time_slider[1].value_end,    \n",
    "    reference_time_start=reference_time_slider[1].value_start,    \n",
    "    reference_time_end=reference_time_slider[1].value_end,\n",
    "    value_min=threshold_selector.value,    \n",
    "    attribute_paths=attribute_paths,\n",
    "    return_query=False,\n",
    ")\n",
    "display(ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf1982-f48f-421d-a0e8-1e1513da83c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
