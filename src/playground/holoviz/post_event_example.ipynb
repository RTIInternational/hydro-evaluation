{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f28e53-63b8-48e1-8017-0c4c85997cae",
   "metadata": {},
   "source": [
    "## Post Event Example - Explore Forecast Data from a Recent Flood Event\n",
    "\n",
    "Add more text description about this use case....\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777e449-4585-453a-be09-84e2a98645ae",
   "metadata": {},
   "source": [
    "### Install and Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb49e8e-989d-4de3-ba03-928f6ade9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install spatialpandas colormap colorcet duckdb\n",
    "#!pip install 'teehr @ git+https://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@github.com/RTIInternational/teehr@main'\n",
    "!pip install 'teehr @ git+https://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@github.com/RTIInternational/teehr@39d6627e4f49b0bdeab3a4c4e8837e6ce5a15f78'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efca43-3791-4e08-a82e-73e0b571ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teehr.queries.duckdb as tqd\n",
    "\n",
    "# dashboard functions\n",
    "import dashboard_utils as dbu\n",
    "import importlib\n",
    "importlib.reload(dbu)\n",
    "\n",
    "from datetime import timedelta\n",
    "import pathlib\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import spatialpandas as spd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd8c25e-e0e8-4e9c-9021-9899d8e2b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews.element import tiles\n",
    "import geoviews as gv\n",
    "import panel as pn\n",
    "import colorcet as cc\n",
    "from holoviews.operation.datashader import rasterize, spread\n",
    "hv.extension('bokeh', logo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379e40e-e39b-4e58-81c5-002c16353973",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specify the parquet files for this study\n",
    "First we need to specify all the parquet files containing the data we want to evaluate, as well as some necessary associated data (geometry, crosswalks, and attributes).\n",
    "These files dictate the specific study (directory name), forecast configuration, and source of verifying data used in this evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe30fb-e7d3-424c-ad8c-bb22bf29bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY_DIR = pathlib.Path(\"/home/jovyan/shared/rti-eval/post-event-example\")\n",
    "\n",
    "PRIMARY_FILEPATH_FORCING   = STUDY_DIR / \"timeseries\" / \"forcing_analysis_assim\" / \"*.parquet\"\n",
    "SECONDARY_FILEPATH_FORCING = STUDY_DIR / \"timeseries\" / \"forcing_medium_range\" / \"*.parquet\"\n",
    "CROSSWALK_FILEPATH_FORCING = STUDY_DIR / \"geo\" / \"huc10_huc10_crosswalk.parquet\"                 # the primary and secondary are both HUC10\n",
    "GEOMETRY_FILEPATH_FORCING  = STUDY_DIR / \"geo\" / \"huc10_geometry.parquet\"\n",
    "\n",
    "PRIMARY_FILEPATH_STREAMFLOW   = STUDY_DIR / \"timeseries\" / \"usgs\" / \"*.parquet\"\n",
    "SECONDARY_FILEPATH_STREAMFLOW = STUDY_DIR / \"timeseries\" / \"medium_range_mem1\" / \"*.parquet\"\n",
    "CROSSWALK_FILEPATH_STREAMFLOW = STUDY_DIR / \"geo\" / \"usgs_nwm22_crosswalk.parquet\"\n",
    "GEOMETRY_FILEPATH_STREAMFLOW  = STUDY_DIR / \"geo\" / \"usgs_geometry.parquet\"\n",
    "\n",
    "ATTRIBUTES_FILEPATH_UPSTREAM_AREA       = STUDY_DIR / \"geo\" / \"usgs_attr_upstream_area.parquet\"\n",
    "ATTRIBUTES_FILEPATH_ECOREGIONS          = STUDY_DIR / \"geo\" / \"usgs_attr_ecoregions.parquet\"\n",
    "#ATTRIBUTES_FILEPATH_UPSTREAM_IMPERVIOUS = STUDY_DIR / \"geo\" / \"usgs_attr_upstream_imperv.parquet\"    # don't have this data yet\n",
    "\n",
    "CROSSWALK_FILEPATH_USGS_HUC10 = STUDY_DIR / \"geo\" / \"usgs_huc10_crosswalk.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80112507-ff41-472e-82fc-c067aa5ea0db",
   "metadata": {},
   "source": [
    "#####  \n",
    "### Read the associated geometry, crosswalks and attribute data\n",
    "Text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8aaf07-0626-4b34-8f65-06adc52e10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify general units (english or metric) to show in visualization\n",
    "viz_units = \"metric\"\n",
    "\n",
    "## Read points geometry to plot static background points\n",
    "cross_df = pd.read_parquet(pathlib.Path(CROSSWALK_FILEPATH_USGS_HUC10))\n",
    "points_gdf = gpd.read_parquet(pathlib.Path(GEOMETRY_FILEPATH_STREAMFLOW))\n",
    "\n",
    "# add easting and northing to point geom to simplify overlays\n",
    "points_gdf['easting'] = points_gdf.to_crs(\"EPSG:3857\").geometry.x\n",
    "points_gdf['northing'] = points_gdf.to_crs(\"EPSG:3857\").geometry.y\n",
    "\n",
    "## specify list of attributes to include (from those available)\n",
    "ATTRIBUTES_FILELIST_STREAMFLOW = [\n",
    "    ATTRIBUTES_FILEPATH_UPSTREAM_AREA,\n",
    "    ATTRIBUTES_FILEPATH_ECOREGIONS,  \n",
    "   #ATTRIBUTES_FILEPATH_UPSTREAM_IMPERVIOUS\n",
    "]\n",
    "\n",
    "attr_df = dbu.combine_attributes(ATTRIBUTES_FILELIST_STREAMFLOW, viz_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fba77-49ef-481c-b296-24b6c756beb9",
   "metadata": {},
   "source": [
    "#####\n",
    "### Check the dates of available data and select the event period to evaluate\n",
    "Next we will check the dates available in the parquet files, and use a slider to select all or a portion of the total available period to evaluate.   \n",
    "  (ToDo: create utility to check that data are complete for all of the above defined timeseries files between the min/max dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fcb64-70ab-48dd-96b8-fe53f8b0712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date, max_date = dbu.get_parquet_date_range_across_sources(\n",
    "    [\n",
    "    PRIMARY_FILEPATH_FORCING, \n",
    "    SECONDARY_FILEPATH_FORCING,\n",
    "    PRIMARY_FILEPATH_STREAMFLOW,\n",
    "    SECONDARY_FILEPATH_STREAMFLOW,\n",
    "    ])\n",
    "\n",
    "slider_instructions = \"Adjust the start and end dates on the slider below to define overall desired event period:\"\n",
    "event_dates_slider = dbu.get_event_date_range_slider(min_date- timedelta(hours = 1), max_date, dict(width = 800))\n",
    "event_text = dbu.get_event_dates_text(min_date- timedelta(hours = 1), max_date)\n",
    "pn.Column(\n",
    "    pn.Spacer(background='white', height=20), \n",
    "    pn.pane.HTML(slider_instructions, style={'font-size': '18px', 'font-weight': 'bold'}),\n",
    "    event_text, \n",
    "    event_dates_slider,\n",
    "    pn.Spacer(background='white', height=20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1675719-47cb-4dd8-8a44-c2d04fc21ac5",
   "metadata": {},
   "source": [
    "### Select a specific reference time to explore within the event period\n",
    "\n",
    "For an initial example, we will select a single reference time to explore the comparison between forecast and observed data.  Later we will use this widget more interactively in a dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf774a4-71b0-4b8a-8c44-61bedd48cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_time_player = dbu.get_reference_time_player_selected_dates(\n",
    "    start = event_dates_slider.value_start - timedelta(hours = 1),\n",
    "    end = event_dates_slider.value_end)\n",
    "\n",
    "player_instructions = \"User the slider or forward arrow (arrow with line) to select a reference time:\"\n",
    "current_ref_time = pn.bind(dbu.get_reference_time, reference_time=reference_time_player.param.value)\n",
    "pn.Column(\n",
    "    pn.Spacer(background='white', height=20), \n",
    "    pn.pane.HTML(player_instructions, style={'font-size': '18px', 'font-weight': 'bold'}),    \n",
    "    current_ref_time, reference_time_player, \n",
    "    pn.Spacer(background='white', height=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c55fcf-e746-40fd-afd1-4625547aae1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Now we'll get some data to evaluate... \n",
    "###  We will run an example TEEHR query that will \n",
    "1) Read the forecast timeseries from the parquet cache for the defined configuration (secondary_filepath) and reference time (selected above)\n",
    "2) Read the 'observed' timeseries from the cache for the defined verifying data source (primary_filepath)\n",
    "3) Join the primary to the secondary timeseries, aligning the data by value_time\n",
    "4) Calculate and return some basic timeseries and comparison metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b382f21-29ea-4477-b5e5-2fd9e93c8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list metrics to keep in the results - \n",
    "    # Note that a single forecast contains insufficient data for statistical comparisons\n",
    "    # need to describe all available somewhere\n",
    "    # will use a wrapper to generate the query filter - later in notebook\n",
    "\n",
    "metric_list = ['primary_average','secondary_average'] #'primary_max','primary_min','secondary_max','secondary_min'\n",
    "\n",
    "gdf = tqd.get_metrics(\n",
    "    primary_filepath=PRIMARY_FILEPATH_STREAMFLOW,\n",
    "    secondary_filepath=SECONDARY_FILEPATH_STREAMFLOW,\n",
    "    crosswalk_filepath=CROSSWALK_FILEPATH_STREAMFLOW,\n",
    "    group_by=[\"reference_time\", \"primary_location_id\",\"measurement_unit\"],\n",
    "    order_by=[\"reference_time\", \"primary_location_id\"],\n",
    "    filters=[{\n",
    "            \"column\": \"reference_time\",\n",
    "            \"operator\": \"=\",\n",
    "            \"value\": f\"{reference_time_player.value}\"\n",
    "        },\n",
    "        {\n",
    "            \"column\": \"primary_value\",\n",
    "            \"operator\": \">=\",\n",
    "            \"value\": 0\n",
    "        },\n",
    "        {\n",
    "            \"column\": \"secondary_value\",\n",
    "            \"operator\": \">=\",\n",
    "            \"value\": 0\n",
    "        }\n",
    "    ],\n",
    "    return_query=False,\n",
    "    geometry_filepath=GEOMETRY_FILEPATH_STREAMFLOW,         \n",
    "    include_geometry=True,\n",
    ")\n",
    "# reduce columns and get the difference\n",
    "gdf = gdf[[\"reference_time\", \"primary_location_id\",\"measurement_unit\",\"geometry\"] + metric_list]\n",
    "gdf['perc_diff'] = (gdf['secondary_average'] - gdf['primary_average']) / gdf['primary_average'] * 100\n",
    "\n",
    "# convert units if needed\n",
    "gdf = dbu.convert_metrics_to_viz_units(gdf, viz_units)\n",
    "\n",
    "# check it out\n",
    "gdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d564d-626c-49d7-9a85-116bd1db8694",
   "metadata": {},
   "source": [
    "### Now we'll create a simple map of the % difference in peak flow between forecast and observed using hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839da118-f36f-42aa-84a4-2969b194c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(sizing_mode='scale_both')\n",
    "gdf = gdf.to_crs(\"EPSG:3857\")\n",
    "sdf = spd.GeoDataFrame(gdf)\n",
    "title = (f\"Reference Time: {reference_time_player.value}\")\n",
    "diff_map = sdf.hvplot.points(c='perc_diff', cmap=cc.CET_D1A[::-1], clim=(-100,100), width=800, height=400,\n",
    "                             clabel=\"% Difference Peak Flow\", title=title, size=5, xaxis = None, yaxis = None, tiles='OSM')\n",
    "diff_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e212af5-0913-40ac-8838-84172c604285",
   "metadata": {},
   "source": [
    "#### Try changing the reference time selected above and rerunning the query and map a few times  \n",
    "&nbsp;  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37a092-72e9-431d-83de-44adfea0de7a",
   "metadata": {},
   "source": [
    "### Create other basic plots to explore the data more.... link them to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105337ec-9b4c-4776-af87-b200b3164e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# regular dataframe works better for scat, hist, get rid of the huge values that make it hard to see...\n",
    "df = gdf[['primary_location_id','primary_average','secondary_average','perc_diff']].copy()\n",
    "df['easting'] = gdf.geometry.x\n",
    "df['northing'] = gdf.geometry.y\n",
    "df = df.loc[(df['secondary_average']<5000) & (df['primary_average']<5000) & \\\n",
    "            (df['secondary_average']>0) & (df['primary_average']>0)]\n",
    "\n",
    "diff_hist = df.hvplot.hist(y='perc_diff', bins=100, bin_range=(-100, 1000), height=300, width=700, xlabel='% Difference Peak Flow')\n",
    "diff_scat = df.hvplot.scatter(x='secondary_average', y='primary_average', height=300, width=400, xlabel='Forecast Peak', ylabel='Observed Peak')\n",
    "ls = hv.link_selections.instance()\n",
    "ls(diff_scat + diff_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ae9af4-d7e2-4874-9753-063cc1c9ffd9",
   "metadata": {},
   "source": [
    "### Link them up with the map..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772348b-28e7-4e95-abe1-522040c572e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "measure='perc_diff'\n",
    "width = 700\n",
    "basemap = osm2 = tiles.OSM().redim(x='easting', y='northing') #gv.tile_sources.CartoLight\n",
    "points_hv = hv.Points(df, kdims=['easting','northing'], vdims=[measure, 'secondary_average', 'primary_average'])\n",
    "points_hv.opts(width=width, height=400, color=hv.dim(measure), clim=(-100,100),\n",
    "    cmap=cc.CET_D1A[::-1], size = 5, xaxis=None, yaxis=None, colorbar=True)\n",
    "\n",
    "diff_hist = df.hvplot.hist(y=measure, width=width, bins=100, bin_range=(-100, 1000), height=200, xlabel='% Difference Peak Flow')\n",
    "#diff_scat = df.hvplot.scatter(x='secondary_average', y='primary_average', vdims=[measure,'easting','northing'], alpha=0.2, width=400, height=400, xlabel='Forecast Peak', ylabel='Observed Peak')\n",
    "diff_scat = hv.Scatter(df, kdims=['secondary_average'], vdims=['primary_average','easting','northing',measure])\n",
    "diff_scat.opts(alpha=0.2, width=400, height=400, xlabel='Forecast Peak', ylabel='Observed Peak')\n",
    "ls = hv.link_selections.instance()\n",
    "ls((basemap*points_hv + diff_scat + diff_hist)).cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa09c7-01b2-464d-a9d9-36848bea1482",
   "metadata": {},
   "source": [
    "### Add some additional attributes and generate different plots\n",
    "\n",
    "normalize flows, add linked histogram of upstream area and/or ecoregion..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c508c3-448e-4307-a068-17899fafc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merge = dbu.merge_attr_to_gdf(gdf, attr_df)\n",
    "gdf_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26914c-13e5-407f-ab4a-38f202dfac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize flows to upstream area for comparability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8db537-d27b-4e61-8faf-5e1bbed4cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  work on 3 way map.... add precip... add timeseries\n",
    "\n",
    "pn.extension(sizing_mode='scale_both')\n",
    "prim_map = sdf.hvplot.points(c='primary_average', cmap=cc.CET_L8[::-1], cnorm='eq_hist', clim=(0,15000), width=400,\n",
    "                             clabel=\"Peak Flow (cfs)\", title=title, size=5, xaxis = None, yaxis = None, tiles='CartoLight')\n",
    "sec_map = sdf.hvplot.points(c='secondary_average', cmap=cc.CET_L8[::-1], cnorm='eq_hist', clim=(0,15000), width=400,\n",
    "                             clabel=\"Peak Flow (cfs)\", title=title, size=5, xaxis = None, yaxis = None, tiles='CartoLight')\n",
    "\n",
    "prim_map + sec_map + basemap*points_hv.opts(width=400, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea7be8-a605-422b-8813-e6b89ff1384a",
   "metadata": {},
   "source": [
    "To do:\n",
    "build up 3-col explorer layout  ...add precip... add timeseries from prior notebook   \n",
    "turn into a dashboard at end  \n",
    "try other scatter layouts, find best for alt dashboard - decide between these two for demo (prob only time for 1 post event example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004171ac-94f8-4406-b7a5-d78392a304b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dbu)\n",
    "\n",
    "# metric query wrapper\n",
    "gdf = dbu.get_comparison_metrics(\n",
    "    primary_filepath=PRIMARY_FILEPATH_STREAMFLOW,\n",
    "    secondary_filepath=SECONDARY_FILEPATH_STREAMFLOW,\n",
    "    crosswalk_filepath=CROSSWALK_FILEPATH_STREAMFLOW,\n",
    "    geometry_filepath=GEOMETRY_FILEPATH_STREAMFLOW,      \n",
    "    single_reference_time=reference_time_player.value,    \n",
    "    query_value_min=0,\n",
    ")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a76d02-480f-49bf-8f55-12758aae435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  will need another wrapper around the above to generate the holoviews element, like in prior notebooks, but with new query wrapper structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93dfb9-1b7d-4a57-8536-cf4abe9e3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  stuff below is remnants - reworking dashboards based on above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d7820-57bb-441a-ae6b-2125131a0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## add normalized flow\n",
    "# max_gdf['primary_ave_norm'] = merge_gdf['primary_average'] / merge_gdf['attribute_value'] * 3600 * 12\n",
    "# max_gdf['secondary_ave_norm'] = merge_gdf['secondary_average'] / merge_gdf['attribute_value'] * 3600 * 12\n",
    "\n",
    "# # subset data based on requested min/max (if any defined, e.g., only > 0 or other threshold)\n",
    "# if measure_min_requested:\n",
    "#     data_gdf = data_gdf[data_gdf[measure] >= measure_min_requested]\n",
    "# if measure_max_requested:\n",
    "#     data_gdf = data_gdf[data_gdf[measure] <= measure_max_requested]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee947059-ee6a-4c67-8636-f24483544a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### General plotting options\n",
    "\n",
    "flow_measure = \"max_in_hr\"\n",
    "flow_map_title = \"Normalized Event Peak Flow (in/hr)\"  \n",
    "precip_map_title = \"Total Precipitation (in)\"\n",
    "\n",
    "if flow_measure == \"max_recurr_int\":\n",
    "    points_cmap_opts = dict(cmap=dbs.get_recurr_colormap(), legend_position='bottom_right')\n",
    "else:\n",
    "    points_cmap_opts = dict(cmap=cc.CET_L8[::-1], cnorm='eq_hist', colorbar=True) \n",
    "    \n",
    "map_opts = dict(show_grid=False, xaxis = None, yaxis = None)\n",
    "curve_opts = dict(toolbar = None, tools=[\"hover\"], show_title = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1fb58-3dc4-4d34-bb53-6ecc946a1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Build components for the dashboard\n",
    "\n",
    "# Build background (static) map Elements - background tiles and all gage points \n",
    "# for reference on rasterized catchments DynamicMap\n",
    "tiles_background = gv.tile_sources.CartoLight.opts(**map_opts, toolbar = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66351ca1-96af-4567-b3da-542bd7b18335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#points_background \n",
    "# points_background = hv.Points(points_gdf, kdims = ['easting','northing'], vdims = ['id']).opts(color='lightgray', size=2, toolbar='right')\n",
    "# points = spread(rasterize(points_background), px=4, shape='circle').opts(cmap=[\"lightgray\"]) #, responsive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea85035-2b30-404c-8019-184e5f222da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension(sizing_mode='stretch_width')\n",
    "\n",
    "layout = pn.Column(\n",
    "    pn.Column(current_ref_time, reference_time_player),\n",
    "    #pn.Row(pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0)),\n",
    "    #pn.Row(pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0), pn.panel(tiles_background * points, margin=0)),\n",
    "    pn.Row(pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0)),\n",
    "    pn.Row(pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0), pn.panel(tiles_background, margin=0)),\n",
    "    pn.Spacer(background='green', height=150, margin=0),\n",
    "    pn.Spacer(background='red', height=150, margin=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039a299-8a0c-4d8f-9c7d-9b1cc069cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gspec = pn.GridSpec(sizing_mode='stretch_width', width_policy='max', height=900)\n",
    "\n",
    "# gspec[0,:] = pn.Column(current_ref_time, reference_time_player, margin=5)\n",
    "# gspec[1:4,0] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[1:4,1] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[1:4,2] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[4:7,0] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[4:7,1] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[4:7,2] = pn.panel(tiles_background, margin=0)\n",
    "# gspec[7,:] = pn.Spacer(background='green',  margin=0)\n",
    "# gspec[8,:] = pn.Spacer(background='red',  margin=0)\n",
    "\n",
    "# gspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ace93-6fc0-4de6-9409-4459b63f1aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f367d-4a0d-4c61-8480-03fb433ea594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c8158-4cd8-4608-8d1b-4707953210ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32ff88-7e76-434b-84b1-468b93c64aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
