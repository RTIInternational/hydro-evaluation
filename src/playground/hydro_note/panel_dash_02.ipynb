{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2438f-b1cb-4863-91f1-cab875985357",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spatialpandas easydev colormap colorcet duckdb dask_geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f1fd2-fd18-4e92-b65b-26a50f8e7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#DATA_DIR = \"/Users/ctownsend/projects/hydro_data/data/studies\"\n",
    "# adding project dirs to path so code may be referenced from the notebook\n",
    "sys.path.insert(0, '../../')\n",
    "sys.path.insert(0, '../../evaluation/')\n",
    "sys.path.insert(0, '../../evaluation/queries/')\n",
    "\n",
    "from evaluation import utils, config\n",
    "import queries # need to fix path to use original queries\n",
    "import dask_geopandas\n",
    "import duckdb as ddb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8e3b8-43e7-44e2-ac11-82b523531c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import holoviews as hv, geoviews as gv, param, dask.dataframe as dd, cartopy.crs as crs\n",
    "import panel as pn\n",
    "from datetime import datetime as dt\n",
    "from bokeh.models import HoverTool\n",
    "#import datetime as dt\n",
    "import datashader as ds\n",
    "from spatialpandas import GeoSeries, GeoDataFrame\n",
    "from colormap import rgb2hex\n",
    "import logging\n",
    "from shapely.geometry import Point\n",
    "import dask\n",
    "import geopandas \n",
    "from evaluation import utils, config\n",
    "import queries # need to fix path to use original queries\n",
    "import dask_geopandas\n",
    "\n",
    "from colorcet import cm\n",
    "from holoviews.operation.datashader import rasterize, shade, regrid, inspect_points\n",
    "from holoviews.operation.datashader import (\n",
    "    datashade, inspect_polygons\n",
    ")\n",
    "from holoviews.streams import RangeXY, Pipe, Tap, Selection1D\n",
    "from holoviews.util.transform import easting_northing_to_lon_lat\n",
    "import pandas as pd\n",
    "\n",
    "hv.extension('bokeh', logo=False)\n",
    "opts = dict(width=700,\n",
    "            height=500,\n",
    "            #xaxis=None,\n",
    "            #yaxis=None,\n",
    "            #bgcolor='black',\n",
    "            show_grid=False)\n",
    "cmaps = ['fire','bgy','bgyw','bmy','gray','kbc']\n",
    "\n",
    "\n",
    "class HydroExplorer(param.Parameterized):\n",
    "    renderer = hv.renderer('bokeh')\n",
    "    _basins_gdf = utils.parquet_to_gdf(config.HUC10_PARQUET_FILEPATH)\n",
    "    _rslt = geopandas.GeoDataFrame(columns=['geometry', 'huc10', 'name', 'reference_time', 'catchment_id', 'value_time', 'forecast_value', 'observed_value', 'forecast_average', 'observed_average'], geometry='geometry')\n",
    "    pn.extension(loading_spinner='dots', loading_color='#00aa41', sizing_mode=\"stretch_width\")\n",
    "\n",
    "    def _get_defaults():\n",
    "        query = f\"\"\"select distinct(reference_time)as _time\n",
    "            from '{config.MEDIUM_RANGE_FORCING_PARQUET}/*.parquet'\n",
    "            order by reference_time desc\"\"\"\n",
    "        time_df = ddb.query(query).to_df()\n",
    "        \n",
    "        return time_df['_time'].iloc[0], time_df['_time'].iloc[-1], time_df._time.tolist()\n",
    "        \n",
    "    _min_time, \\\n",
    "    _max_time, \\\n",
    "    time_list = _get_defaults()\n",
    "    _min_bias = -0.0004960052998526384 # need to do a per huc2 calculation for these\n",
    "    _max_bias = 0.0003667801712634422\n",
    "    \n",
    "    measure    = param.ObjectSelector(default='bias', objects=['bias','max_forecast_delta', 'observed_variance', 'forecast_variance', 'observed_average', 'forecast_average'])\n",
    "    huc2       = param.ObjectSelector(default='01', objects=['all','01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18'])\n",
    "    time       = param.ObjectSelector(default=_min_time, objects=list(time_list))\n",
    "\n",
    "    _tap_stream = Tap(transient=False)\n",
    "\n",
    "    def get_catchment_details(self, catchment_id, _time=None):\n",
    "        filters = []\n",
    "        if len(catchment_id) == 2:\n",
    "            filters.append(\n",
    "                {\n",
    "                    \"column\": \"catchment_id\",\n",
    "                    \"operator\": \"like\",\n",
    "                    \"value\": \"\" + catchment_id + \"%\"\n",
    "                }\n",
    "            )\n",
    "        elif len(catchment_id) > 3:\n",
    "            filters.append(\n",
    "                {\n",
    "                    \"column\": \"catchment_id\",\n",
    "                    \"operator\": \"=\",\n",
    "                    \"value\": catchment_id\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        if _time is not None:\n",
    "            filters.append(\n",
    "                {\n",
    "                    \"column\": \"reference_time\",\n",
    "                    \"operator\": \"=\",\n",
    "                    \"value\": \"\" + str(_time) + \"\"\n",
    "                }  \n",
    "            )\n",
    "\n",
    "        query = queries.calculate_catchment_metrics(\n",
    "            config.MEDIUM_RANGE_FORCING_PARQUET,\n",
    "            config.FORCING_ANALYSIS_ASSIM_PARQUET,\n",
    "            group_by=[\"reference_time, catchment_id\"],\n",
    "            order_by=[\"reference_time, catchment_id\"],\n",
    "            filters=filters\n",
    "        )\n",
    "        df = ddb.query(query).to_df()\n",
    "        gdf_map = self._basins_gdf.merge(df, left_on=\"huc10\", right_on=\"catchment_id\")\n",
    "        return gdf_map\n",
    "    \n",
    "    @param.depends('measure', 'huc2','time')\n",
    "    def get_polygon(self):\n",
    "        rslt_df = self.get_catchment_details(self.huc2, self.time)\n",
    "        self._rslt = rslt_df\n",
    "        rslt_df = rslt_df.to_crs(\"EPSG:3857\")\n",
    "        rslt_df['name'] = rslt_df['name'].astype('category')\n",
    "        \n",
    "        max_bias, min_bias = self._max_bias, self._min_bias\n",
    "        \n",
    "        polygon = gv.Polygons(GeoDataFrame(rslt_df), #hover functionality needs spatialpandas dataframe to work\n",
    "                              crs=crs.GOOGLE_MERCATOR, #needed for tooltips to work\n",
    "                              vdims=[self.measure, 'name', 'catchment_id'])\n",
    "        \n",
    "        if self.measure == 'bias':\n",
    "            polygon = polygon.redim.range(bias=(min_bias,max_bias))\n",
    "\n",
    "        return polygon.opts(width=700,height=500)\n",
    "\n",
    "    \n",
    "    @param.depends('huc2', 'measure')\n",
    "    def map_plot(self):\n",
    "        polygon = hv.DynamicMap(self.get_polygon)#, kdims=['huc2','time']).redim.values(huc2=self.huc_list, time=self.time_list).opts(framewise=True)\n",
    "        shaded = rasterize(polygon, aggregator=ds.min(self.measure))\n",
    "        shaded.opts(tools=['tap'], alpha=0.75, colorbar=True)\n",
    "        \n",
    "        tooltips=[('Name', '@name'), ('Catchment ID', '@catchment_id'), (self.measure, '@' + self.measure)]\n",
    "        hover_tool = HoverTool(tooltips=tooltips)\n",
    "        hover = inspect_polygons(shaded).opts(fill_color='yellow', tools=[hover_tool,'tap']).opts(alpha=0.9)\n",
    "        self._tap_stream.source = shaded\n",
    "        tiles = gv.tile_sources.StamenTerrain().apply.opts(alpha=0.75, **opts)\n",
    "        return (tiles * shaded * hover).opts(width=700,height=500)\n",
    "        \n",
    "    def get_table_dmap(self):\n",
    "        return hv.DynamicMap(self.plot_table, streams=[self._tap_stream])\n",
    "\n",
    "    def plot_table(self,x,y):\n",
    "        if x is None:\n",
    "            x,y = 0,0\n",
    "        x,y = easting_northing_to_lon_lat(x, y)\n",
    "        pnt = Point(x, y)\n",
    "        rslt = self._rslt[(self._rslt.contains(pnt) == True)]\n",
    "        if len(rslt) > 0:\n",
    "            rslt = self.get_catchment_details(rslt['catchment_id'].iloc[0])\n",
    "        \n",
    "        target_fields = ['huc10', 'name', 'reference_time', 'catchment_id', \n",
    "                         'intercept', 'covariance', 'corr', 'r_squared', \n",
    "                         'forecast_count', 'observed_count', 'forecast_average', 'observed_average', \n",
    "                         'forecast_variance', 'observed_variance', 'max_forecast_delta', 'bias']\n",
    "        return hv.Table(rslt[target_fields])\n",
    "\n",
    "    @pn.depends(_tap_stream.param.x,_tap_stream.param.y)\n",
    "    def plot_forecast_diff(self,x,y):\n",
    "        if x is None:\n",
    "            x,y = 0,0\n",
    "        x,y = easting_northing_to_lon_lat(x, y)\n",
    "        pnt = Point(x, y)\n",
    "        rslt = self._rslt[(self._rslt.contains(pnt) == True)]\n",
    "\n",
    "        if len(rslt) > 0:\n",
    "            rslt = self.get_catchment_details(rslt['catchment_id'].iloc[0])\n",
    "\n",
    "        target_fields = ['name', 'reference_time', 'forecast_average', 'observed_average']\n",
    "        rslt = rslt[target_fields]\n",
    "\n",
    "        forecast_avg = hv.Curve(rslt, 'reference_time', 'forecast_average', label='forecast_average')\n",
    "        forecast_avg.opts(tools=['hover'], color=\"orange\")\n",
    "        observed_avg = hv.Curve(rslt, 'reference_time', 'observed_average', label='observed_average').opts(tools=['hover'], color=\"blue\")\n",
    "        viz = forecast_avg * observed_avg\n",
    "        viz.opts(width=1200)\n",
    "        label = \"\"\n",
    "        if rslt.empty == False:\n",
    "            label = rslt['name'].iloc[0]\n",
    "        return viz.relabel(label)\n",
    "\n",
    "    def get_joined_catchment_timeseries(self, catchment_id, _time):\n",
    "        query = queries.get_joined_catchment_timeseries(\n",
    "        config.MEDIUM_RANGE_FORCING_PARQUET,\n",
    "        config.FORCING_ANALYSIS_ASSIM_PARQUET,\n",
    "        filters=[\n",
    "            {\n",
    "                \"column\": \"reference_time\",\n",
    "                \"operator\": \"=\",\n",
    "                \"value\": \"\" + str(_time) + \"\"\n",
    "            },\n",
    "            {\n",
    "                \"column\": \"catchment_id\",\n",
    "                \"operator\": \"=\",\n",
    "                \"value\": catchment_id\n",
    "            },\n",
    "        ]\n",
    "        )\n",
    "        df = ddb.query(query).to_df()\n",
    "        return df\n",
    "    \n",
    "    @pn.depends(_tap_stream.param.x,_tap_stream.param.y)\n",
    "    def plot_joined_catchment_timeseries(self, x, y):\n",
    "        label = \"\"\n",
    "        if x is None:\n",
    "            x,y = 0,0\n",
    "        x,y = easting_northing_to_lon_lat(x, y)\n",
    "        pnt = Point(x, y)\n",
    "        rslt = self._rslt[(self._rslt.contains(pnt) == True)]\n",
    "\n",
    "        if len(rslt) > 0:\n",
    "            label = rslt['name'].iloc[0] + \" (\" + str(rslt['catchment_id'].iloc[0]) + \")\"\n",
    "            rslt = self.get_joined_catchment_timeseries(rslt['catchment_id'].iloc[0], self.time)\n",
    "\n",
    "        forecast_val = hv.Curve(rslt, 'value_time', 'forecast_value', label='forecast_value')\n",
    "        forecast_val.opts(tools=['hover'], color=\"orange\")\n",
    "        observed_val = hv.Curve(rslt, 'value_time', 'observed_value', label='observed_value').opts(tools=['hover'], color=\"blue\")\n",
    "        viz = forecast_val * observed_val\n",
    "        viz.opts(width=1200)\n",
    "        #if rslt.empty == False:\n",
    "        #    label = rslt['name'].iloc[0]\n",
    "        return viz.relabel(label)\n",
    "\n",
    "    def get_joined_catchment_timeseries_table_dmap(self):\n",
    "        return hv.DynamicMap(self.joined_catchment_timeseries_table, streams=[self._tap_stream])\n",
    "\n",
    "    def joined_catchment_timeseries_table(self, x, y):\n",
    "        label = \"\"\n",
    "        if x is None:\n",
    "            x,y = 0,0\n",
    "        x,y = easting_northing_to_lon_lat(x, y)\n",
    "        pnt = Point(x, y)\n",
    "        rslt = self._rslt[(self._rslt.contains(pnt) == True)]\n",
    "\n",
    "        if len(rslt) > 0:\n",
    "            label = rslt['name'].iloc[0] + \" (\" + str(rslt['catchment_id'].iloc[0]) + \")\"\n",
    "            rslt = self.get_joined_catchment_timeseries(rslt['catchment_id'].iloc[0], self.time)\n",
    "\n",
    "            target_fields = ['reference_time', 'value_time', 'catchment_id', 'forecast_value', 'configuration', \n",
    "                             'measurement_unit', 'variable_name', 'observed_value', 'lead_time']\n",
    "            rslt = rslt[target_fields]\n",
    "        return hv.Table(rslt)\n",
    "\n",
    "\n",
    "hydro = HydroExplorer(name=\"Map Explorer\")\n",
    "\n",
    "pn.Column(pn.Row(pn.panel(hydro.map_plot, loading_indicator=True),\n",
    "          pn.Param(hydro.param, \n",
    "                   widgets={'time': pn.widgets.DiscretePlayer})\n",
    "          , sizing_mode=\"stretch_both\"),\n",
    "#          hydro.plot_forecast_diff,\n",
    "          pn.panel(hydro.plot_joined_catchment_timeseries, loading_indicator=True),\n",
    "#         hydro.get_table_dmap().opts(width=1200)\n",
    "         pn.panel(hydro.get_joined_catchment_timeseries_table_dmap, loading_indicator=True)).servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
