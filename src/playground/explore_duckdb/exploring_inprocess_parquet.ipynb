{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70171dd-4a94-4060-b4d3-de8f1a435f01",
   "metadata": {},
   "source": [
    "# Exploring in-process query options for Parquet \n",
    "This notebook explores using datafusion and DuckDB for querying Parquet data files holding NWM, xref, and usgs actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec5c48-a835-432d-9d7f-4f7760f01906",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting initial parquet data for the NWM\n",
    "\n",
    "This first code block will run for a while and generate the parquet files for the time period specified in the script.\n",
    "\n",
    "The code block then moves the parquet files to data/nwm/ to keep track of which parquet files are associated with particular output; as there will be multiple sets of parquet files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d55c70-e179-4f7e-b673-b81891c5e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was actually run from a bash prompt prior to the current placement into the explore folder\n",
    "# may need to be tweaked to get the path right\n",
    "!cd ../hydro-evaluation/parquet\n",
    "!#python3 nwm_to_parquet.py #commented out so it isn't run by accident\n",
    "! cd ../..\n",
    "! mkdir -p data/nwm/\n",
    "!#mv parquet/*.parquet data/nwm/ #prevent run by accident\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a01b5-419c-4add-bb40-34205bb35225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding project dirs to path so code may be referenced from the notebook\n",
    "import sys\n",
    "sys.path.insert(0, '../hydro-evaluation/wide_table')\n",
    "sys.path.insert(0, '../hydro-evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f44e44-c1fa-4d7a-a239-db92e6cefe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28363a19-3a33-4805-b7fd-a986650cbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../hydro-evaluation/data/RouteLink_CONUS_NWMv2.1.6.csv\"\n",
    "xwalk_data = utils.get_xwalk(file)\n",
    "xwalk_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9082e-6338-490b-bd4a-1788080398e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "xwalk_data2 = utils.get_xwalk() #tests original method without file path\n",
    "xwalk_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1231aa6-a44a-4557-8568-eb057b5843e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f57a4c-f980-49a6-847a-dcddc8dbc293",
   "metadata": {},
   "outputs": [],
   "source": [
    "xwalk_data.to_parquet(\"../hydro-evaluation/data/xwalk.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ef807-2c8e-4def-8c34-00c03fbcb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HDF5_DIR=/opt/homebrew/opt/hdf5\n",
    "!pip3 install hydrotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226116a7-1683-4028-b16c-682dd3b49253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicating the ingest_usgs code here so the data may be\n",
    "# saved as parquet data rather than inserted into the timeseriesDB\n",
    "from hydrotools.nwis_client.iv import IVDataService\n",
    "from datetime import datetime, timedelta\n",
    "from insert_usgs import fetch_usgs\n",
    "\n",
    "start = datetime(2022, 10, 1)\n",
    "download_period = timedelta(days=1)\n",
    "number_of_periods = 30\n",
    "\n",
    "for p in range(number_of_periods):\n",
    "    print(\"Processing: \", p)\n",
    "    start_dt = (start + download_period * p)\n",
    "    end_dt = (start + download_period * (p + 1))\n",
    "    start_dt_str = start_dt.strftime(\"%Y-%m-%d\")\n",
    "    end_dt_str = end_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    observations_data = fetch_usgs(\n",
    "        start_dt=start_dt_str,\n",
    "        end_dt=end_dt_str\n",
    "    )\n",
    "    \n",
    "    observations_data.set_index(\"value_time\", inplace=True)\n",
    "    obs = observations_data[\n",
    "        observations_data.index.hour.isin(range(0, 23)) \n",
    "        & (observations_data.index.minute == 0) \n",
    "        & (observations_data.index.second == 0)\n",
    "    ]\n",
    "    obs.reset_index(level=0, allow_duplicates=True, inplace=True)\n",
    "    obs.to_parquet(\"../hydro-evaluation/data/usgs/\" + str(p) + \".parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbc1d1-b1d4-48b9-8aaf-73f1ca9a4439",
   "metadata": {},
   "source": [
    "# loading sampe data from TimescaleDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088583a6-3342-4e0a-b340-140b23dbf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "query1_head = pd.read_csv(\"query1_head.csv\")\n",
    "\n",
    "query1_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f4685-70d2-4ee4-bcdf-23554856ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2_head = pd.read_csv(\"query2_head.csv\")\n",
    "\n",
    "query2_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2e2b7-6539-46bb-ab39-5da5176936ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3_head = pd.read_csv(\"query3_head.csv\")\n",
    "\n",
    "query3_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9992e016-d058-4329-9748-c98552f45be3",
   "metadata": {},
   "source": [
    "# Exploring datafusion\n",
    "A SQL engine on top of various file formats including Parquet; does not yet have enough stats functions to be immediately useful via SQL; \n",
    "## results\n",
    "- consumed all available memory for query1 and then failed; ran for a very long time\n",
    "- tried to modify query many different ways with same result\n",
    "- for some reason, query planner did not like simple in statement; couldn't find any documentation for why this would be a problem\n",
    "- do not recommend as it is too brittle and not as memory efficient as advertised for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e57e9-1dfb-4bc5-9920-74349d36c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install datafusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598054e-3a8f-4d21-b8da-b04e80473b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datafusion as df\n",
    "ctx = df.SessionContext()\n",
    "\n",
    "ctx.register_parquet('nd', '../hydro-evaluation/data/nwm/*.parquet')\n",
    "ctx.register_parquet('nux', '../hydro-evaluation/data/xwalk.parquet')\n",
    "ctx.register_parquet('ud', '../hydro-evaluation/data/usgs/*.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61a270-8210-4b5b-a39f-3b88fd5a864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datafusion import col\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT nd.reference_time,\n",
    "        nd.value_time,\n",
    "        nd.nwm_feature_id,   \n",
    "        nd.value as forecast_value, \n",
    "        nd.configuration,  \n",
    "        nd.measurement_unit,     \n",
    "        nd.variable_name,\n",
    "        nux.latitude,\n",
    "        nux.longitude,\n",
    "        ud.value as observed_value,\n",
    "        ud.usgs_site_code\n",
    "    FROM nd \n",
    "    JOIN nux \n",
    "        on nux.nwm_feature_id = nd.nwm_feature_id \n",
    "    JOIN ud \n",
    "        on nux.usgs_site_code  = ud.usgs_site_code \n",
    "        and nd.value_time = ud.value_time \n",
    "        and nd.measurement_unit = ud.measurement_unit\n",
    "        and nd.variable_name = ud.variable_name\n",
    "                    where nd.nwm_feature_id in (select 6731199,2441678,14586327,8573705,2567762,41002752,8268521,41026212,4709060,20957306)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "query = \"\"\"\n",
    "    select nd.reference_time,\n",
    "        nd.value_time,\n",
    "        nd.nwm_feature_id,   \n",
    "        nd.value as forecast_value, \n",
    "        nd.configuration,  \n",
    "        nd.measurement_unit,     \n",
    "        nd.variable_name,\n",
    "        nux.latitude,\n",
    "        nux.longitude\n",
    "    from nd\n",
    "    join nux \n",
    "        on nux.nwm_feature_id = nd.nwm_feature_id\n",
    "    JOIN ud \n",
    "        on nux.usgs_site_code  = ud.usgs_site_code \n",
    "        and nd.value_time = ud.value_time \n",
    "        and nd.measurement_unit = ud.measurement_unit\n",
    "        and nd.variable_name = ud.variable_name\n",
    "    where nd.nwm_feature_id in (select 6731199,2441678,14586327,8573705,2567762,41002752,8268521,41026212,4709060,20957306)\n",
    "\"\"\"\n",
    "df = ctx.sql(query)\n",
    "df.show()\n",
    "#df.filter(col(\"nwm_feature_id\") == 6731199)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f39de-1598-49b2-a7f2-e639aa4f457c",
   "metadata": {},
   "source": [
    "# exploring DuckDB\n",
    "\n",
    "## results\n",
    "- very efficent use of memory; never much more than the memory allocated for the notebook service\n",
    "- very fast query execution and fetch times\n",
    "- query planner had no problems with any of the existing or modified SQL statements\n",
    "- additional performance tuning possibilities down the road, things similar to materialized views\n",
    "- integrates really well with Python and other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90fa090-8fe4-4cdc-bd57-9a0f363e872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c16a0-8324-44bc-8bed-a7ad0756d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as ddb\n",
    "con = ddb.connect(database='explore.duckdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cfb44-e9d4-4ba7-a0ca-5b9312dc7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    with joined as (\n",
    "        SELECT \n",
    "        nd.reference_time,\n",
    "        nd.value_time,\n",
    "        nd.nwm_feature_id,   \n",
    "        nd.value as forecast_value, \n",
    "        nd.configuration,  \n",
    "        nd.measurement_unit,     \n",
    "        nd.variable_name,\n",
    "        --nux.geom as geom, \n",
    "        ud.value as observed_value,\n",
    "        ud.usgs_site_code,\n",
    "        nd.value_time - nd.reference_time as lead_time\n",
    "        FROM '../hydro-evaluation/data/nwm/*.parquet'  nd \n",
    "        JOIN '../hydro-evaluation/data/xwalk.parquet'  nux \n",
    "        on nux.nwm_feature_id = nd.nwm_feature_id \n",
    "        JOIN '../hydro-evaluation/data/usgs/*.parquet'  ud \n",
    "        on nux.usgs_site_code  = ud.usgs_site_code \n",
    "        and nd.value_time = ud.value_time \n",
    "        and nd.measurement_unit = ud.measurement_unit\n",
    "        and nd.variable_name = ud.variable_name\n",
    "        where nd.nwm_feature_id in (6731199,2441678,14586327,8573705,2567762,41002752,8268521,41026212,4709060,20957306)\n",
    "    )\n",
    "    select \n",
    "    reference_time, \n",
    "    nwm_feature_id,\n",
    "    regr_intercept(forecast_value, observed_value) as intercept,\n",
    "    covar_pop(forecast_value, observed_value) as covariance,\n",
    "    corr(forecast_value, observed_value) as corr,\n",
    "    regr_r2(forecast_value, observed_value) as r_squared,\n",
    "    count(forecast_value) as forecast_count,\n",
    "    count(observed_value) as observed_count,\n",
    "    avg(forecast_value) as forecast_average,\n",
    "    avg(observed_value) as observed_average,\n",
    "    var_pop(forecast_value) as forecast_variance,\n",
    "    var_pop(observed_value) as observed_variance,\n",
    "    sum(observed_value - forecast_value)/count(*) as bias,\n",
    "    max(forecast_value) - max(observed_value) as max_forecast_delta\n",
    "    from joined \n",
    "    group by reference_time, nwm_feature_id\n",
    "    order by nwm_feature_id, max_forecast_delta;\n",
    "\"\"\"\n",
    "\n",
    "query1_df = con.execute(query).df()\n",
    "query1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd539f-8364-4e32-b5a1-215d71f7c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = query1_df.pivot(index=\"reference_time\", columns=\"nwm_feature_id\", values=\"bias\")\n",
    "bias.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e046457-f3f7-4158-8bb7-8ff87108a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwm_feature_id = 17003262\n",
    "configuration = 'medium_range_mem1'\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT \n",
    "    nd.reference_time,\n",
    "    nd.nwm_feature_id,   \n",
    "    nd.value_time,\n",
    "    regr_intercept(nd.value, ud.value) as intercept,\n",
    "    covar_pop(nd.value, ud.value) as covariance,\n",
    "    corr(nd.value, ud.value) as corr,\n",
    "    regr_r2(nd.value, ud.value) as r_squared,\n",
    "    count(nd.value) as forecast_count,\n",
    "    count(ud.value) as observed_count,\n",
    "    avg(nd.value) as forecast_average,\n",
    "    avg(ud.value) as observed_average,\n",
    "    var_pop(nd.value) as forecast_variance,\n",
    "    var_pop(ud.value) as observed_variance,\n",
    "    max(nd.value) - max(ud.value) as max_forecast_delta,\n",
    "    sum(ud.value - nd.value)/count(*) as bias\n",
    "    FROM '../hydro-evaluation/data/nwm/*.parquet'  nd \n",
    "    JOIN '../hydro-evaluation/data/xwalk.parquet'  nux \n",
    "        on nux.nwm_feature_id = nd.nwm_feature_id \n",
    "    JOIN '../hydro-evaluation/data/usgs/*.parquet'  ud \n",
    "        on nux.usgs_site_code  = ud.usgs_site_code \n",
    "        and nd.value_time = ud.value_time \n",
    "        and nd.measurement_unit = ud.measurement_unit\n",
    "        and nd.variable_name = ud.variable_name\n",
    "    where nd.nwm_feature_id = {nwm_feature_id}\n",
    "    and configuration = '{configuration}'\n",
    "    group by nd.reference_time,\n",
    "    nd.nwm_feature_id,   \n",
    "    nd.value_time\n",
    "\"\"\"\n",
    "query2_df = con.execute(query).df()\n",
    "query2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78cde3-62b8-4992-a254-b4d19a242a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    nd.reference_time,\n",
    "    nd.value_time,\n",
    "    nd.nwm_feature_id,   \n",
    "    nd.value as forecast_value, \n",
    "    nd.configuration,  \n",
    "    nd.measurement_unit,     \n",
    "    nd.variable_name,\n",
    "    nux.latitude,\n",
    "    nux.longitude,\n",
    "    ud.value as observed_value,\n",
    "    ud.usgs_site_code,\n",
    "    nd.value_time - nd.reference_time as lead_time\n",
    "FROM '../hydro-evaluation/data/nwm/*.parquet'  nd \n",
    "JOIN '../hydro-evaluation/data/xwalk.parquet'  nux \n",
    "    on nux.nwm_feature_id = nd.nwm_feature_id \n",
    "JOIN '../hydro-evaluation/data/usgs/*.parquet'  ud \n",
    "    on nux.usgs_site_code  = ud.usgs_site_code \n",
    "    and nd.value_time = ud.value_time \n",
    "    and nd.measurement_unit = ud.measurement_unit\n",
    "    and nd.variable_name = ud.variable_name\n",
    "where configuration = 'medium_range_mem1'\n",
    "and nd.nwm_feature_id = 17003262\n",
    "order by reference_time, nd.nwm_feature_id;\n",
    "\"\"\"\n",
    "query3_df = con.execute(query).df()\n",
    "query3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94718828-997f-49b1-83b8-808cf92b6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.gca()\n",
    "query3_df.plot(x= 'value_time', y=\"forecast_value\", ax = ax, figsize=(20,10))\n",
    "query3_df.plot(x= 'value_time', y=\"observed_value\", ax = ax, figsize=(20,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a01878-348d-46d9-a619-7efc68e28bf6",
   "metadata": {},
   "source": [
    "# Next steps?\n",
    "- Initial example dashboard with larger data set for DuckDB?\n",
    "- Dash appears to be a better choice:\n",
    "    - subjectively dashboard examples look better out of the box on demo sites\n",
    "    - stack would be easier to customize if needed: Python, Flask, Plotly, React\n",
    "    - supports multiple languages: Python, R, Julia\n",
    "- How best to handle geospatial data types?\n",
    "    - Geospatial data types are not yet part of DuckDB, looks like it is being discussed in their issues/tickets\n",
    "    - Explore GeoParquet with GeoPandas(extension of Pandas for geospatial types and operations)\n",
    "    - SpatiaLite as option to investigate handling of geospatial data with another query to DuckDB parquet data\n",
    "    - GDAL/Parquet handling\n",
    "    - Potential for a linked server between SpatiaLite and DuckDB with a view in DuckDB to all the Parquet data exposed to SpatiaLite for handling geospatial conversions\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
